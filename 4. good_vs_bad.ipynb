{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from utils.preprocessing import get_texts\n",
    "from utils.preprocessing import get_texts, stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modify here for different sectors and score_types\n",
    "# set the sector and ESG type for the analysis\n",
    "# sector = \"Industrials\"\n",
    "sector = \"Energy\"\n",
    "# sector = \"Energy\"\n",
    "\n",
    "# score_type = \"governanceScore\"\n",
    "score_type = \"environmentScore\"\n",
    "# score_type = \"socialScore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esg_score = pd.read_excel(\"data/esg_score.xlsx\", sheet_name = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Consumer Cyclical', 'Energy', 'Industrials', 'Healthcare',\n",
       "       'Basic Materials', 'Consumer Defensive', 'Utilities', 'Technology',\n",
       "       'Financial Services', 'Communication Services', 'Real Estate'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_esg_score[\"sector\"].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"combination\": [], \"bad_tickers\": [], \"good_tickers\": []}\n",
    "\n",
    "for sec in df_esg_score[\"sector\"].dropna().unique():\n",
    "    for s_type in [\"governanceScore\", \"environmentScore\", \"socialScore\"]:\n",
    "        tickers = df_esg_score[df_esg_score[\"sector\"] == sec][\"Company\"]\n",
    "        esgs = df_esg_score[df_esg_score[\"sector\"] == sec][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "        score = esgs[s_type]\n",
    "        alpha = 0.25\n",
    "        upper_score = np.quantile(score, 1 - alpha)\n",
    "        lower_score = np.quantile(score, alpha)\n",
    "\n",
    "        bad_companies = esgs[esgs[s_type] > upper_score][\"Company\"].values\n",
    "        good_companies = esgs[esgs[s_type] < lower_score][\"Company\"].values\n",
    "\n",
    "        # print(sec)\n",
    "        d[\"combination\"].append(sec + \"_\" + s_type)\n",
    "        d[\"good_tickers\"].append(','.join(good_companies))\n",
    "        d[\"bad_tickers\"].append(','.join(bad_companies))\n",
    "\n",
    "ddf = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.to_csv(\"data/goodvbad/goodcbad_companies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get texts for companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = df_esg_score[df_esg_score[\"sector\"] == sector][\"Company\"]\n",
    "esgs = df_esg_score[df_esg_score[\"sector\"] == sector][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = esgs[score_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3\n",
    "upper_score = np.quantile(score, 1 - alpha)\n",
    "lower_score = np.quantile(score, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_companies = esgs[esgs[score_type] > upper_score][\"Company\"].values\n",
    "good_companies = esgs[esgs[score_type] < lower_score][\"Company\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOV', 'OKE', 'HAL', 'SLB', 'WMB', 'KMI'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COG', 'MRO', 'CVX', 'EOG', 'APA', 'OXY'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>socialScore</th>\n",
       "      <th>governanceScore</th>\n",
       "      <th>environmentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COG</td>\n",
       "      <td>14.01</td>\n",
       "      <td>9.28</td>\n",
       "      <td>23.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MRO</td>\n",
       "      <td>10.27</td>\n",
       "      <td>8.70</td>\n",
       "      <td>23.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVX</td>\n",
       "      <td>10.67</td>\n",
       "      <td>10.21</td>\n",
       "      <td>20.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EOG</td>\n",
       "      <td>11.06</td>\n",
       "      <td>8.24</td>\n",
       "      <td>19.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>APA</td>\n",
       "      <td>8.88</td>\n",
       "      <td>7.96</td>\n",
       "      <td>21.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OXY</td>\n",
       "      <td>10.85</td>\n",
       "      <td>6.75</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company  socialScore  governanceScore  environmentScore\n",
       "1      COG        14.01             9.28             23.39\n",
       "3      MRO        10.27             8.70             23.76\n",
       "4      CVX        10.67            10.21             20.29\n",
       "7      EOG        11.06             8.24             19.67\n",
       "8      APA         8.88             7.96             21.98\n",
       "10     OXY        10.85             6.75             20.00"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esgs[esgs[score_type] > upper_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_companies_score = esgs[esgs[score_type] > upper_score][score_type].values\n",
    "good_companies_score = esgs[esgs[score_type] < lower_score][score_type].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.515 9.834999999999999\n"
     ]
    }
   ],
   "source": [
    "avg_bad = np.mean(bad_companies_score)\n",
    "avg_good = np.mean(good_companies_score)\n",
    "print(avg_bad, avg_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.376 14.691\n"
     ]
    }
   ],
   "source": [
    "print(upper_score, lower_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))\n",
    "good_cik = []\n",
    "bad_cik = []\n",
    "for ticker in good_companies:    \n",
    "    try:\n",
    "        # for a given ticker, find its cik number through th ticker library\n",
    "        good_cik.append(ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:])\n",
    "    except:\n",
    "        # if could not find cik, give it a empty cik\n",
    "        good_cik.append('')\n",
    "\n",
    "for ticker in bad_companies:    \n",
    "    try:\n",
    "        # for a given ticker, find its cik number through th ticker library\n",
    "        bad_cik.append(ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:])\n",
    "    except:\n",
    "        # if could not find cik, give it a empty cik\n",
    "        bad_cik.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:01,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "ret_good = get_texts(good_cik, good_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:02,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "ret_bad = get_texts(bad_cik, bad_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_docs = ret_good[\"docs\"]\n",
    "bad_docs = ret_bad[\"docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# TODO: Modify here for different ngram range\n",
    "n_min = 2\n",
    "n_max = 3\n",
    "cv = CountVectorizer(max_df=0.6, stop_words=stop_words, max_features=200, ngram_range=(n_min, n_max))\n",
    "word_count_vector = cv.fit_transform(good_docs + bad_docs)\n",
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_feature = word_count_vector.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"word\": [], \"good_score\": [], \"bad_score\": [], \"good_score_all\": []\n",
    "    , \"bad_score_all\": [], \"count\": [], \"good_nums\": [], \"bad_nums\": []}\n",
    "\n",
    "for feature_idx, word in enumerate(feature_names):\n",
    "    good_sum = bad_sum = good_num = bad_num = 0\n",
    "\n",
    "    for i, doc_set in enumerate(good_docs):\n",
    "        if word in doc_set:\n",
    "            good_num += 1\n",
    "            good_sum += good_companies_score[i]\n",
    "    for i, doc_set in enumerate(bad_docs):\n",
    "        if word in doc_set:\n",
    "            bad_num += 1\n",
    "            bad_sum += bad_companies_score[i]\n",
    "    \n",
    "    # print(\"word: {}\".format(word))\n",
    "    d[\"word\"].append(word) \n",
    "    \n",
    "    if good_num:\n",
    "        d[\"good_score\"].append(good_sum / good_num)\n",
    "    else:\n",
    "        d[\"good_score\"].append(0)\n",
    "    if bad_num:\n",
    "        d[\"bad_score\"].append(bad_sum / bad_num)\n",
    "    else:\n",
    "        d[\"bad_score\"].append(0)\n",
    "\n",
    "    d[\"good_score_all\"].append(good_sum / len(good_docs))\n",
    "    d[\"bad_score_all\"].append(bad_sum / len(bad_docs))\n",
    "\n",
    "    d[\"count\"].append(count_feature[feature_idx])\n",
    "    d[\"good_nums\"].append(good_num)\n",
    "    d[\"bad_nums\"].append(bad_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accompanying note consolidated</td>\n",
       "      <td>13.830</td>\n",
       "      <td>21.886667</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>10.943333</td>\n",
       "      <td>1143</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accompanying note integral</td>\n",
       "      <td>10.545</td>\n",
       "      <td>21.705000</td>\n",
       "      <td>3.515000</td>\n",
       "      <td>14.470000</td>\n",
       "      <td>1584</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adjusted ebitda</td>\n",
       "      <td>10.975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.316667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1051</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adopted pursuant</td>\n",
       "      <td>9.294</td>\n",
       "      <td>21.880000</td>\n",
       "      <td>7.745000</td>\n",
       "      <td>7.293333</td>\n",
       "      <td>1043</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adopted pursuant section</td>\n",
       "      <td>9.294</td>\n",
       "      <td>21.880000</td>\n",
       "      <td>7.745000</td>\n",
       "      <td>7.293333</td>\n",
       "      <td>1037</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             word  good_score  bad_score  good_score_all  \\\n",
       "0  accompanying note consolidated      13.830  21.886667        2.305000   \n",
       "1      accompanying note integral      10.545  21.705000        3.515000   \n",
       "2                 adjusted ebitda      10.975   0.000000        7.316667   \n",
       "3                adopted pursuant       9.294  21.880000        7.745000   \n",
       "4        adopted pursuant section       9.294  21.880000        7.745000   \n",
       "\n",
       "   bad_score_all  count  good_nums  bad_nums  \n",
       "0      10.943333   1143          1         3  \n",
       "1      14.470000   1584          2         4  \n",
       "2       0.000000   1051          4         0  \n",
       "3       7.293333   1043          5         2  \n",
       "4       7.293333   1037          5         2  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diff\"] = abs(df[\"good_nums\"] - df[\"bad_nums\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"diff\", ascending=False)#.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>isGood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accompanying note consolidated</td>\n",
       "      <td>13.830000</td>\n",
       "      <td>21.886667</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>10.943333</td>\n",
       "      <td>1143</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accompanying note integral</td>\n",
       "      <td>10.545000</td>\n",
       "      <td>21.705000</td>\n",
       "      <td>3.515000</td>\n",
       "      <td>14.470000</td>\n",
       "      <td>1584</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adjusted ebitda</td>\n",
       "      <td>10.975000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.316667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1051</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adopted pursuant</td>\n",
       "      <td>9.294000</td>\n",
       "      <td>21.880000</td>\n",
       "      <td>7.745000</td>\n",
       "      <td>7.293333</td>\n",
       "      <td>1043</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adopted pursuant section</td>\n",
       "      <td>9.294000</td>\n",
       "      <td>21.880000</td>\n",
       "      <td>7.745000</td>\n",
       "      <td>7.293333</td>\n",
       "      <td>1037</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>among williams</td>\n",
       "      <td>8.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.496667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1164</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>analysis continued</td>\n",
       "      <td>8.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.496667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1269</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apache corporation</td>\n",
       "      <td>8.765000</td>\n",
       "      <td>20.550000</td>\n",
       "      <td>2.921667</td>\n",
       "      <td>10.275000</td>\n",
       "      <td>3760</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>apache corporation subsidiary</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.663333</td>\n",
       "      <td>1711</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>attributable common</td>\n",
       "      <td>8.765000</td>\n",
       "      <td>20.990000</td>\n",
       "      <td>2.921667</td>\n",
       "      <td>6.996667</td>\n",
       "      <td>1139</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>attributable common stock</td>\n",
       "      <td>8.765000</td>\n",
       "      <td>20.990000</td>\n",
       "      <td>2.921667</td>\n",
       "      <td>6.996667</td>\n",
       "      <td>1061</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>attributable company</td>\n",
       "      <td>10.170000</td>\n",
       "      <td>22.685000</td>\n",
       "      <td>3.390000</td>\n",
       "      <td>7.561667</td>\n",
       "      <td>897</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>available common</td>\n",
       "      <td>10.453333</td>\n",
       "      <td>21.332500</td>\n",
       "      <td>5.226667</td>\n",
       "      <td>14.221667</td>\n",
       "      <td>1087</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>beginning page</td>\n",
       "      <td>10.040000</td>\n",
       "      <td>21.777500</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>14.518333</td>\n",
       "      <td>1030</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>border pipeline</td>\n",
       "      <td>11.190000</td>\n",
       "      <td>23.760000</td>\n",
       "      <td>3.730000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>919</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bp exploration</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>21.980000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>3.663333</td>\n",
       "      <td>886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>brokered natural</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.898333</td>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>brokered natural gas</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.898333</td>\n",
       "      <td>881</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>brown root</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>953</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cabot oil</td>\n",
       "      <td>8.980000</td>\n",
       "      <td>23.390000</td>\n",
       "      <td>1.496667</td>\n",
       "      <td>3.898333</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              word  good_score  bad_score  good_score_all  \\\n",
       "0   accompanying note consolidated   13.830000  21.886667        2.305000   \n",
       "1       accompanying note integral   10.545000  21.705000        3.515000   \n",
       "2                  adjusted ebitda   10.975000   0.000000        7.316667   \n",
       "3                 adopted pursuant    9.294000  21.880000        7.745000   \n",
       "4         adopted pursuant section    9.294000  21.880000        7.745000   \n",
       "5                   among williams    8.980000   0.000000        1.496667   \n",
       "6               analysis continued    8.980000   0.000000        1.496667   \n",
       "7               apache corporation    8.765000  20.550000        2.921667   \n",
       "8    apache corporation subsidiary    0.000000  21.980000        0.000000   \n",
       "9              attributable common    8.765000  20.990000        2.921667   \n",
       "10       attributable common stock    8.765000  20.990000        2.921667   \n",
       "11            attributable company   10.170000  22.685000        3.390000   \n",
       "12                available common   10.453333  21.332500        5.226667   \n",
       "13                  beginning page   10.040000  21.777500        5.020000   \n",
       "14                 border pipeline   11.190000  23.760000        3.730000   \n",
       "15                  bp exploration    7.800000  21.980000        1.300000   \n",
       "16                brokered natural    0.000000  23.390000        0.000000   \n",
       "17            brokered natural gas    0.000000  23.390000        0.000000   \n",
       "18                      brown root    7.800000   0.000000        1.300000   \n",
       "19                       cabot oil    8.980000  23.390000        1.496667   \n",
       "\n",
       "    bad_score_all  count  good_nums  bad_nums  isGood  \n",
       "0       10.943333   1143          1         3      -1  \n",
       "1       14.470000   1584          2         4      -1  \n",
       "2        0.000000   1051          4         0       1  \n",
       "3        7.293333   1043          5         2       1  \n",
       "4        7.293333   1037          5         2       1  \n",
       "5        0.000000   1164          1         0       0  \n",
       "6        0.000000   1269          1         0       0  \n",
       "7       10.275000   3760          2         3       0  \n",
       "8        3.663333   1711          0         1       0  \n",
       "9        6.996667   1139          2         2       0  \n",
       "10       6.996667   1061          2         2       0  \n",
       "11       7.561667    897          2         2       0  \n",
       "12      14.221667   1087          3         4       0  \n",
       "13      14.518333   1030          3         4       0  \n",
       "14       3.960000    919          2         1       0  \n",
       "15       3.663333    886          1         1       0  \n",
       "16       3.898333    885          0         1       0  \n",
       "17       3.898333    881          0         1       0  \n",
       "18       0.000000    953          1         0       0  \n",
       "19       3.898333   1203          1         1       0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodvbad_path = os.path.join(\"data\", \"goodvbad\")\n",
    "if not os.path.isdir(goodvbad_path):\n",
    "    os.mkdir(goodvbad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.round(2).to_csv(\"data/goodvbad/{}_{}_{}_n{}-{}.csv\".format(sector[:8], score_type[:3], alpha, n_min, n_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove all the previous files earlier than 2020\n",
    "for cik in tqdm(bad_cik):\n",
    "    tenk_path = os.path.join(\"data\", \"10k\", cik, \"rawtext\")\n",
    "    all_raws = os.listdir(tenk_path)\n",
    "    for filename in all_raws:\n",
    "        if filename[0] == '.':\n",
    "            continue\n",
    "        year = int(filename.split('_')[1].split('-')[0])\n",
    "        # print(year)\n",
    "        if year < 2020:\n",
    "            # print(os.path.join(tenk_path, filename))\n",
    "            os.remove(os.path.join(tenk_path, filename))\n",
    "    \n",
    "    tenq_path = os.path.join(\"data\", \"10q\", cik, \"rawtext\")\n",
    "    all_raws = os.listdir(tenq_path)\n",
    "    for filename in all_raws:\n",
    "        if filename[0] == '.':\n",
    "            continue\n",
    "        year = int(filename.split('_')[1].split('-')[0])\n",
    "        # print(year)\n",
    "        if year < 2020:\n",
    "            # print(os.path.join(tenk_path, filename))\n",
    "            os.remove(os.path.join(tenq_path, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the previous incompleted scraping\n",
    "dirname = os.path.join(\"data\", \"10q\")\n",
    "all_files = os.listdir(dirname)\n",
    "\n",
    "import shutil\n",
    "for filename in all_files:\n",
    "    pkldir = os.path.join(dirname, filename, \"pickle\")\n",
    "    if os.path.isdir(pkldir):\n",
    "        if not os.path.exists(os.path.join(pkldir, \"agg_texts.pkl\")):\n",
    "            shutil.rmtree(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"energy_good_vs_bad_uni_bi_tri.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accompanying note consolidated</td>\n",
       "      <td>9.773333</td>\n",
       "      <td>23.7600</td>\n",
       "      <td>4.886667</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accompanying note integral</td>\n",
       "      <td>10.557500</td>\n",
       "      <td>21.6950</td>\n",
       "      <td>7.038333</td>\n",
       "      <td>7.231667</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acmp</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.9800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.663333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>activity cash flow</td>\n",
       "      <td>10.975000</td>\n",
       "      <td>21.0660</td>\n",
       "      <td>7.316667</td>\n",
       "      <td>17.555000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusted ebitda</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.2825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.855000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             word  good_score  bad_score  good_score_all  \\\n",
       "0  accompanying note consolidated    9.773333    23.7600        4.886667   \n",
       "1      accompanying note integral   10.557500    21.6950        7.038333   \n",
       "2                            acmp    0.000000    21.9800        0.000000   \n",
       "3              activity cash flow   10.975000    21.0660        7.316667   \n",
       "4                 adjusted ebitda    0.000000    22.2825        0.000000   \n",
       "\n",
       "   bad_score_all  good_nums  bad_nums  diff  \n",
       "0       3.960000          3         1     2  \n",
       "1       7.231667          4         2     2  \n",
       "2       3.663333          0         1     1  \n",
       "3      17.555000          4         5     1  \n",
       "4      14.855000          0         4     4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.read_csv(\"data/sp500_component_stocks.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79    Citigroup Inc.\n",
       "Name: Agilent Technologies Inc., dtype: object"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp[comp['A'] == \"C\"][\"Agilent Technologies Inc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44                   Apache Corporation\n",
       "111         Cabot Oil & Gas Corporation\n",
       "128                 Chevron Corporation\n",
       "163                  EOG Resources Inc.\n",
       "322            Marathon Oil Corporation\n",
       "358    Occidental Petroleum Corporation\n",
       "Name: Agilent Technologies Inc., dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp[comp['A'].isin(good_companies)][\"Agilent Technologies Inc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215            Halliburton Company\n",
       "274      Kinder Morgan Inc Class P\n",
       "343    National Oilwell Varco Inc.\n",
       "354                     ONEOK Inc.\n",
       "411                Schlumberger NV\n",
       "487        Williams Companies Inc.\n",
       "Name: Agilent Technologies Inc., dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp[comp['A'].isin(bad_companies)][\"Agilent Technologies Inc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cik(ticker):\n",
    "    \"\"\" Get the cik for the ticker specified by the input argument \n",
    "    Input:\n",
    "        ticker(str): ticker of the company e.g. \"FB\"\n",
    "    \"\"\"\n",
    "    print(ticker)\n",
    "    return ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ciks(tickers):\n",
    "    ciks = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        ciks.append(get_cik(ticker))\n",
    "\n",
    "    return ciks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(s, n):\n",
    "    \"\"\" Get all the n-gram for input texts s\n",
    "    Input:\n",
    "        s (str): A string of texts with each word separated by a whitespace\n",
    "        n (int): n-gram to extract\n",
    "    Return:\n",
    "        [str]: A list of string in the following format ([['a', 'b'], ['b', 'c'], ['c', 'd']])\n",
    "    \"\"\"\n",
    "    \n",
    "    s = s.split(' ')\n",
    "    output = []\n",
    "    for i in range(len(s) - n + 1):\n",
    "        output.append(s[i:i+n])\n",
    "\n",
    "    return output\n",
    "\n",
    "# ngrams('a b c d', 2) # [['a', 'b'], ['b', 'c'], ['c', 'd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"accompanying note consolidated\" in df[\"word\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(doc, df_dict, n_min, n_max):\n",
    "    \"\"\" Count the number of good and bad words occurred in the document\n",
    "    Input:\n",
    "        doc (str): A string with all the words in the documents\n",
    "        df_dict (pd.DataFrame): A DataFrame with word and isGood column, generated by previous section\n",
    "        n_min, n_max (int): specify the ngram range used to generate the dictionary, should be consistent with how df_dict is generated\n",
    "    Return:\n",
    "        (dict): A dictionary with value good_count and bad_count\n",
    "    \"\"\"\n",
    "    grams = []\n",
    "    for n in range(n_min, n_max + 1):\n",
    "        grams.extend([' '.join(li) for li in ngrams(doc, 2)])\n",
    "    \n",
    "    good_count = bad_count = 0\n",
    "    \n",
    "    for g in grams:\n",
    "        if g in df_dict[\"word\"].values:\n",
    "            val = df_dict[df_dict[\"word\"] == g][\"isGood\"].values\n",
    "            if val == 1:\n",
    "                good_count += 1\n",
    "            elif val == -1:\n",
    "                bad_count += 1\n",
    "\n",
    "    return {\"good_count\": good_count, \"bad_count\": bad_count}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(df_topk, val_tickers, dict_threshold, val_true):\n",
    "    \"\"\" Perform the validation step\n",
    "    The validation rationale: Companies whose score are in upper 50% group are considered \"bad\" companies and the corresponding val_true = 1; 0 otherwise (in lower 50% group, which is considered a good company)\n",
    "    Input:\n",
    "        df_topk (pd.DataFrame): containes the sector specific dict\n",
    "        val_tickers (list): A list of tickers to be validated\n",
    "        dict_threshold (int): A gram is considered as a good word if its good_nums - bad_nums > threshold\n",
    "        val_true (list): A list of true labels for each companies\n",
    "    \"\"\"\n",
    "    diff = df_topk[\"good_nums\"] - df_topk[\"bad_nums\"]\n",
    "    df_topk[\"isGood\"] = diff.apply(lambda x: 1 if x > dict_threshold else (\n",
    "        -1 if x < -dict_threshold else 0))\n",
    "\n",
    "    # 1 if good_nums - bad_nums > threshold; -1 if good_nums - bad_nums < -threshold; 0 otherwise\n",
    "    val_ciks = [get_cik(ticker) for ticker in val_tickers]\n",
    "    \n",
    "    ret_texts = get_texts(val_ciks, val_tickers) \n",
    "\n",
    "    val_pred = []\n",
    "    for doc in tqdm(ret_texts[\"docs\"]):\n",
    "        ret = get_count(doc, df_topk[[\"word\", \"isGood\"]], 2, 3)\n",
    "\n",
    "        if ret[\"good_count\"] - ret[\"bad_count\"] > 0:\n",
    "            val_pred.append(1)\n",
    "        else:\n",
    "            val_pred.append(0)\n",
    "    \n",
    "    print(\"val_pred: {}\".format(val_pred))\n",
    "    cm = confusion_matrix(val_true, val_pred)\n",
    "    print(\"Confusion Matrix: \\n{}\".format(cm))\n",
    "    return val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COG', 'MRO', 'CVX', 'EOG', 'APA', 'OXY'], dtype=object)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tickers = ['NOV', 'OKE', 'HAL', 'SLB', 'WMB', 'KMI']\n",
    "tickers = list(good_companies[:1]) + list(bad_companies[:1])\n",
    "ciks = [get_cik(ticker) for ticker in tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "ret = get_texts(ciks, tickers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_true = [1 for _ in good_companies[:1]] + [0 for _ in bad_companies[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.73it/s]\n",
      "100%|██████████| 2/2 [01:25<00:00, 42.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "[[1 0]\n",
      " [0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "v = validation(df, tickers, 2, val_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_threshold = 1\n",
    "diff = df[\"good_nums\"] - df[\"bad_nums\"]\n",
    "df[\"isGood\"] = diff.apply(lambda x: 1 if x > dict_threshold else (\n",
    "    -1 if x < -dict_threshold else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>isGood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accompanying note consolidated</td>\n",
       "      <td>13.830</td>\n",
       "      <td>21.886667</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>10.943333</td>\n",
       "      <td>1143</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accompanying note integral</td>\n",
       "      <td>10.545</td>\n",
       "      <td>21.705000</td>\n",
       "      <td>3.515000</td>\n",
       "      <td>14.470000</td>\n",
       "      <td>1584</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adjusted ebitda</td>\n",
       "      <td>10.975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.316667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1051</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adopted pursuant</td>\n",
       "      <td>9.294</td>\n",
       "      <td>21.880000</td>\n",
       "      <td>7.745000</td>\n",
       "      <td>7.293333</td>\n",
       "      <td>1043</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adopted pursuant section</td>\n",
       "      <td>9.294</td>\n",
       "      <td>21.880000</td>\n",
       "      <td>7.745000</td>\n",
       "      <td>7.293333</td>\n",
       "      <td>1037</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             word  good_score  bad_score  good_score_all  \\\n",
       "0  accompanying note consolidated      13.830  21.886667        2.305000   \n",
       "1      accompanying note integral      10.545  21.705000        3.515000   \n",
       "2                 adjusted ebitda      10.975   0.000000        7.316667   \n",
       "3                adopted pursuant       9.294  21.880000        7.745000   \n",
       "4        adopted pursuant section       9.294  21.880000        7.745000   \n",
       "\n",
       "   bad_score_all  count  good_nums  bad_nums  isGood  \n",
       "0      10.943333   1143          1         3      -1  \n",
       "1      14.470000   1584          2         4      -1  \n",
       "2       0.000000   1051          4         0       1  \n",
       "3       7.293333   1043          5         2       1  \n",
       "4       7.293333   1037          5         2       1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = get_count(ret[\"docs\"][1], df[[\"word\", \"isGood\"]], 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good_count': 0, 'bad_count': 0}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>isGood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accompanying note consolidated</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accompanying note integral</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adjusted ebitda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adopted pursuant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adopted pursuant section</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>trustee filed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>unconsolidated affiliate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>well incident</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>williams company</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>williams partner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               word  isGood\n",
       "0    accompanying note consolidated      -1\n",
       "1        accompanying note integral      -1\n",
       "2                   adjusted ebitda       1\n",
       "3                  adopted pursuant       1\n",
       "4          adopted pursuant section       1\n",
       "..                              ...     ...\n",
       "195                   trustee filed       0\n",
       "196        unconsolidated affiliate       1\n",
       "197                   well incident       0\n",
       "198                williams company       0\n",
       "199                williams partner       1\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"word\", \"isGood\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate N-grams based on sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = \"Energy\"\n",
    "# sector = \"Energy\"\n",
    "\n",
    "# score_type = \"governanceScore\"\n",
    "score_type = \"environmentScore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sectors = ['Consumer Cyclical', 'Energy', 'Industrials', 'Healthcare',\n",
    "#        'Basic Materials', 'Consumer Defensive', 'Utilities', 'Technology',\n",
    "#        'Financial Services', 'Communication Services', 'Real Estate']\n",
    "sectors = ['Consumer Cyclical', 'Technology', 'Financial Services']\n",
    "score_types = [\"governanceScore\", \"environmentScore\", \"socialScore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_listed = [\"BBWI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/n_grams/Technology_environmentScore.pkl', 'rb') as handle:\n",
    "    feature_names = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accrued unpaid',\n",
       " 'acquired intangible',\n",
       " 'additional information regarding',\n",
       " 'adopted pursuant',\n",
       " 'adopted pursuant section',\n",
       " 'affect financial result',\n",
       " 'allowance credit',\n",
       " 'amortized cost',\n",
       " 'amount senior',\n",
       " 'annual report year',\n",
       " 'average price',\n",
       " 'average selling',\n",
       " 'average selling price',\n",
       " 'benefit pension',\n",
       " 'billion billion',\n",
       " 'cash flow hedge',\n",
       " 'channel partner',\n",
       " 'class action',\n",
       " 'cloud computing',\n",
       " 'cloud license',\n",
       " 'cloud service',\n",
       " 'commercial paper',\n",
       " 'company adopted',\n",
       " 'company also',\n",
       " 'company belief',\n",
       " 'company entered',\n",
       " 'company recorded',\n",
       " 'compared fiscal',\n",
       " 'compared million',\n",
       " 'compared period',\n",
       " 'compared three',\n",
       " 'compared three month',\n",
       " 'comprehensive loss',\n",
       " 'condensed financial',\n",
       " 'condensed financial statement',\n",
       " 'consolidated condensed',\n",
       " 'consolidated condensed financial',\n",
       " 'consolidated statement income',\n",
       " 'consolidated statement operation',\n",
       " 'constant currency',\n",
       " 'contingent consideration',\n",
       " 'continuing operation',\n",
       " 'contract manufacturer',\n",
       " 'convertible debt',\n",
       " 'convertible note',\n",
       " 'corning right',\n",
       " 'cost product',\n",
       " 'currency forward',\n",
       " 'currency forward contract',\n",
       " 'data center',\n",
       " 'december company',\n",
       " 'deferred revenue',\n",
       " 'defined benefit',\n",
       " 'defined benefit pension',\n",
       " 'designated hedging',\n",
       " 'diluted net',\n",
       " 'diluted net income',\n",
       " 'district court',\n",
       " 'due primarily',\n",
       " 'effect result financial',\n",
       " 'end customer',\n",
       " 'ended april',\n",
       " 'ended august',\n",
       " 'ended february',\n",
       " 'ended january',\n",
       " 'ended july',\n",
       " 'ended may',\n",
       " 'ended october',\n",
       " 'enterprise company',\n",
       " 'equity incentive',\n",
       " 'equivalent marketable',\n",
       " 'exhibit filed',\n",
       " 'expense current',\n",
       " 'fair value derivative',\n",
       " 'fasb issued asu',\n",
       " 'financial measure',\n",
       " 'financial statement additional',\n",
       " 'financial statement item',\n",
       " 'financing receivables',\n",
       " 'first nine',\n",
       " 'first nine month',\n",
       " 'first six',\n",
       " 'first six month',\n",
       " 'fiscal company',\n",
       " 'fiscal compared',\n",
       " 'fiscal fiscal',\n",
       " 'fiscal primarily',\n",
       " 'fiscal primarily due',\n",
       " 'fiscal quarter ended',\n",
       " 'flow hedge',\n",
       " 'following provides',\n",
       " 'foreign currency forward',\n",
       " 'free cash',\n",
       " 'gross profit',\n",
       " 'hardware product',\n",
       " 'hewlett packard',\n",
       " 'hewlett packard enterprise',\n",
       " 'income per',\n",
       " 'income per share',\n",
       " 'increase million',\n",
       " 'increased primarily due',\n",
       " 'integrated circuit',\n",
       " 'interest rate swap',\n",
       " 'investment portfolio',\n",
       " 'issued asu',\n",
       " 'item part',\n",
       " 'june company',\n",
       " 'june december',\n",
       " 'june june',\n",
       " 'license agreement',\n",
       " 'license support',\n",
       " 'loan credit',\n",
       " 'manufacturing process',\n",
       " 'march company',\n",
       " 'margin percentage',\n",
       " 'million aggregate',\n",
       " 'million aggregate principal',\n",
       " 'million fiscal',\n",
       " 'month ended april',\n",
       " 'month ended december',\n",
       " 'month ended february',\n",
       " 'month ended january',\n",
       " 'month ended july',\n",
       " 'month ended june',\n",
       " 'month ended march',\n",
       " 'month ended may',\n",
       " 'month ended september',\n",
       " 'month fiscal',\n",
       " 'month period',\n",
       " 'month period ended',\n",
       " 'mutual fund',\n",
       " 'net cash provided',\n",
       " 'net earnings',\n",
       " 'net income per',\n",
       " 'net revenue',\n",
       " 'net sale',\n",
       " 'nine month fiscal',\n",
       " 'note condensed',\n",
       " 'note condensed consolidated',\n",
       " 'note note consolidated',\n",
       " 'notional amount',\n",
       " 'officer pursuant',\n",
       " 'open market',\n",
       " 'open source',\n",
       " 'operating financial',\n",
       " 'operating margin',\n",
       " 'operating result financial',\n",
       " 'operating segment',\n",
       " 'oracle corporation',\n",
       " 'packard enterprise',\n",
       " 'packard enterprise company',\n",
       " 'pension plan',\n",
       " 'per common',\n",
       " 'percentage net',\n",
       " 'period fiscal',\n",
       " 'period prior',\n",
       " 'plan asset',\n",
       " 'preferred stock',\n",
       " 'principal amount senior',\n",
       " 'principal financial',\n",
       " 'privately held',\n",
       " 'product revenue',\n",
       " 'professional service',\n",
       " 'purchased intangible',\n",
       " 'quarter compared',\n",
       " 'quarter first',\n",
       " 'quarter fiscal year',\n",
       " 'rate swap',\n",
       " 'raw material',\n",
       " 'refer note',\n",
       " 'reference exhibit',\n",
       " 'remaining performance',\n",
       " 'remaining performance obligation',\n",
       " 'restricted cash',\n",
       " 'restructuring plan',\n",
       " 'revenue decreased',\n",
       " 'second quarter fiscal',\n",
       " 'segment net',\n",
       " 'semiconductor industry',\n",
       " 'senior note due',\n",
       " 'service provider',\n",
       " 'service revenue',\n",
       " 'software license',\n",
       " 'statement additional',\n",
       " 'statement income',\n",
       " 'statement item',\n",
       " 'statement operation',\n",
       " 'stock repurchase program',\n",
       " 'strategic investment',\n",
       " 'support service',\n",
       " 'term loan',\n",
       " 'term loan credit',\n",
       " 'third quarter fiscal',\n",
       " 'total revenue',\n",
       " 'unaudited condensed',\n",
       " 'unaudited condensed consolidated',\n",
       " 'unrealized loss',\n",
       " 'value derivative',\n",
       " 'year ended december',\n",
       " 'year ended june']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esg_score = pd.read_excel(\"data/esg_score.xlsx\", sheet_name = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sector in sectors:\n",
    "    for score_type in score_types:\n",
    "        esgs = df_esg_score[df_esg_score[\"sector\"] == sector][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "        score = esgs[score_type]\n",
    "        alpha = 0.3\n",
    "        upper_score = np.quantile(score, 1 - alpha)\n",
    "        lower_score = np.quantile(score, alpha)\n",
    "\n",
    "        bad_companies = list(esgs[esgs[score_type] > upper_score][\"Company\"].values)\n",
    "        good_companies = list(esgs[esgs[score_type] < lower_score][\"Company\"].values)\n",
    "\n",
    "        for t in not_listed:\n",
    "            if t in bad_companies:\n",
    "                bad_companies.remove(t)\n",
    "            if t in good_companies:\n",
    "                good_companies.remove(t)\n",
    "\n",
    "        tickers = good_companies + bad_companies\n",
    "        ciks = get_ciks(tickers)\n",
    "        ret = get_texts(ciks, tickers)\n",
    "        docs = ret[\"docs\"]\n",
    "        \n",
    "        n_min = 2\n",
    "        n_max = 3\n",
    "        cv = CountVectorizer(max_df=0.7, stop_words=stop_words, max_features=200, ngram_range=(n_min, n_max))\n",
    "        word_count_vector = cv.fit_transform(docs)\n",
    "        feature_names = cv.get_feature_names()\n",
    "\n",
    "        with open('data/n_grams/{}_{}.pkl'.format(sector, score_type), 'wb') as handle:\n",
    "            pickle.dump(feature_names, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/n_grams/{}_{}.pkl'.format(sector, score_type), 'wb') as handle:\n",
    "    pickle.dump(feature_names, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = df_esg_score[df_esg_score[\"sector\"] == sector][\"Company\"]\n",
    "esgs = df_esg_score[df_esg_score[\"sector\"] == sector][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "ciks = get_ciks(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:05,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "ret = get_texts(ciks, tickers)\n",
    "docs = ret[\"docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# TODO: Modify here for different ngram range\n",
    "n_min = 2\n",
    "n_max = 3\n",
    "cv = CountVectorizer(max_df=0.6, stop_words=stop_words, max_features=200, ngram_range=(n_min, n_max))\n",
    "word_count_vector = cv.fit_transform(docs)\n",
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcf325ffca4e7352bcfac699b7999bb028ddd94d8390136137b75043a4ee01b0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
