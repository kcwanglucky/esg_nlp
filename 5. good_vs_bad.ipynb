{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from utils.preprocessing import get_texts, stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modify here for different sectors and score_types\n",
    "# set the sector and ESG type for the analysis\n",
    "sector = \"Consumer Cyclical\"    # ['Consumer Cyclical', 'Energy', 'Industrials', 'Healthcare', 'Basic Materials', 'Consumer Defensive', 'Utilities', 'Technology', 'Financial Services', 'Communication Services', 'Real Estate']\n",
    "\n",
    "score_type = \"socialScore\"  # ['socialScore', 'governanceScore', 'environmentScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Consumer Cyclical', 'Energy', 'Industrials', 'Healthcare',\n",
       "       'Basic Materials', 'Consumer Defensive', 'Utilities', 'Technology',\n",
       "       'Financial Services', 'Communication Services', 'Real Estate'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_esg_score = pd.read_excel(\"data/esg_score.xlsx\", sheet_name = \"data\")\n",
    "df_esg_score[\"sector\"].dropna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get texts for companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = df_esg_score[df_esg_score[\"sector\"] == sector][\"Company\"]\n",
    "esgs = df_esg_score[df_esg_score[\"sector\"] == sector][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = esgs[score_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3\n",
    "upper_score = np.quantile(score, 1 - alpha)\n",
    "lower_score = np.quantile(score, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_companies = esgs[esgs[score_type] > upper_score][\"Company\"].values\n",
    "good_companies = esgs[esgs[score_type] < lower_score][\"Company\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FBHS', 'IP', 'SEE', 'WHR', 'NKE', 'PKG', 'BLL', 'MHK', 'TSCO',\n",
       "       'LKQ', 'RL', 'APTV', 'BWA', 'VFC', 'GPC', 'LOW', 'HD', 'HAS'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LEG', 'F', 'AMZN', 'GM', 'TSLA', 'NCLH', 'MGM', 'WYNN', 'DPZ',\n",
       "       'DRI', 'EXPE', 'CMG', 'CCL', 'MCD', 'MAR', 'YUM', 'SBUX', 'ROL'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>socialScore</th>\n",
       "      <th>governanceScore</th>\n",
       "      <th>environmentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LEG</td>\n",
       "      <td>17.19</td>\n",
       "      <td>11.23</td>\n",
       "      <td>20.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>F</td>\n",
       "      <td>12.18</td>\n",
       "      <td>9.62</td>\n",
       "      <td>9.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>14.58</td>\n",
       "      <td>9.66</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>GM</td>\n",
       "      <td>12.56</td>\n",
       "      <td>7.67</td>\n",
       "      <td>10.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>17.31</td>\n",
       "      <td>10.20</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company  socialScore  governanceScore  environmentScore\n",
       "0      LEG        17.19            11.23             20.38\n",
       "49       F        12.18             9.62              9.39\n",
       "52    AMZN        14.58             9.66              6.70\n",
       "58      GM        12.56             7.67             10.28\n",
       "59    TSLA        17.31            10.20              2.95"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esgs[esgs[score_type] > upper_score].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_companies_score = esgs[esgs[score_type] > upper_score][score_type].values\n",
    "good_companies_score = esgs[esgs[score_type] < lower_score][score_type].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.261666666666667 4.690555555555555\n"
     ]
    }
   ],
   "source": [
    "avg_bad = np.mean(bad_companies_score)\n",
    "avg_good = np.mean(good_companies_score)\n",
    "print(avg_bad, avg_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.704 6.965999999999999\n"
     ]
    }
   ],
   "source": [
    "print(upper_score, lower_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))\n",
    "good_cik = []\n",
    "bad_cik = []\n",
    "for ticker in good_companies:\n",
    "    try:\n",
    "        # for a given ticker, find its cik number through th ticker library\n",
    "        good_cik.append(ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:])\n",
    "    except:\n",
    "        # if could not find cik, give it a empty cik\n",
    "        good_cik.append('')\n",
    "\n",
    "for ticker in bad_companies:    \n",
    "    try:\n",
    "        # for a given ticker, find its cik number through th ticker library\n",
    "        bad_cik.append(ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:])\n",
    "    except:\n",
    "        # if could not find cik, give it a empty cik\n",
    "        bad_cik.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 20.89it/s]\n"
     ]
    }
   ],
   "source": [
    "ret_good = get_texts(good_cik, good_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping CIK 0001018724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.48s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already scraped CIK 0001018724\n",
      "Already parsed CIK 0001018724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "18it [00:32,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "ret_bad = get_texts(bad_cik, bad_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_docs = ret_good[\"docs\"]\n",
    "bad_docs = ret_bad[\"docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# TODO: Modify here for different ngram range\n",
    "n_min = 2\n",
    "n_max = 3\n",
    "cv = CountVectorizer(max_df=0.8, stop_words=stop_words, max_features=200, ngram_range=(n_min, n_max))\n",
    "word_count_vector = cv.fit_transform(good_docs + bad_docs)\n",
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_feature = word_count_vector.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"word\": [], \"good_score\": [], \"bad_score\": [], \"good_score_all\": []\n",
    "    , \"bad_score_all\": [], \"count\": [], \"good_nums\": [], \"bad_nums\": []}\n",
    "\n",
    "for feature_idx, word in enumerate(feature_names):\n",
    "    good_sum = bad_sum = good_num = bad_num = 0\n",
    "\n",
    "    for i, doc_set in enumerate(good_docs):\n",
    "        if word in doc_set:\n",
    "            good_num += 1\n",
    "            good_sum += good_companies_score[i]\n",
    "    for i, doc_set in enumerate(bad_docs):\n",
    "        if word in doc_set:\n",
    "            bad_num += 1\n",
    "            bad_sum += bad_companies_score[i]\n",
    "    \n",
    "    # print(\"word: {}\".format(word))\n",
    "    d[\"word\"].append(word) \n",
    "    \n",
    "    if good_num:\n",
    "        d[\"good_score\"].append(good_sum / good_num)\n",
    "    else:\n",
    "        d[\"good_score\"].append(0)\n",
    "    if bad_num:\n",
    "        d[\"bad_score\"].append(bad_sum / bad_num)\n",
    "    else:\n",
    "        d[\"bad_score\"].append(0)\n",
    "\n",
    "    d[\"good_score_all\"].append(good_sum / len(good_docs))\n",
    "    d[\"bad_score_all\"].append(bad_sum / len(bad_docs))\n",
    "\n",
    "    d[\"count\"].append(count_feature[feature_idx])\n",
    "    d[\"good_nums\"].append(good_num)\n",
    "    d[\"bad_nums\"].append(bad_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accompanying note</td>\n",
       "      <td>4.636667</td>\n",
       "      <td>13.523077</td>\n",
       "      <td>3.863889</td>\n",
       "      <td>9.766667</td>\n",
       "      <td>978</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adjusted ebitda</td>\n",
       "      <td>4.012500</td>\n",
       "      <td>12.588333</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>4.196111</td>\n",
       "      <td>495</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aggregate principal</td>\n",
       "      <td>4.971333</td>\n",
       "      <td>13.168182</td>\n",
       "      <td>4.142778</td>\n",
       "      <td>8.047222</td>\n",
       "      <td>984</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggregate principal amount</td>\n",
       "      <td>4.971333</td>\n",
       "      <td>13.168182</td>\n",
       "      <td>4.142778</td>\n",
       "      <td>8.047222</td>\n",
       "      <td>915</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annual report year</td>\n",
       "      <td>4.479286</td>\n",
       "      <td>13.190769</td>\n",
       "      <td>3.483889</td>\n",
       "      <td>9.526667</td>\n",
       "      <td>496</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         word  good_score  bad_score  good_score_all  \\\n",
       "0           accompanying note    4.636667  13.523077        3.863889   \n",
       "1             adjusted ebitda    4.012500  12.588333        0.891667   \n",
       "2         aggregate principal    4.971333  13.168182        4.142778   \n",
       "3  aggregate principal amount    4.971333  13.168182        4.142778   \n",
       "4          annual report year    4.479286  13.190769        3.483889   \n",
       "\n",
       "   bad_score_all  count  good_nums  bad_nums  \n",
       "0       9.766667    978         15        13  \n",
       "1       4.196111    495          4         6  \n",
       "2       8.047222    984         15        11  \n",
       "3       8.047222    915         15        11  \n",
       "4       9.526667    496         14        13  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diff\"] = abs(df[\"good_nums\"] - df[\"bad_nums\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"diff\", ascending=False)#.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>raw material</td>\n",
       "      <td>4.558000</td>\n",
       "      <td>14.990000</td>\n",
       "      <td>3.798333</td>\n",
       "      <td>3.331111</td>\n",
       "      <td>801</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>net earnings</td>\n",
       "      <td>4.454615</td>\n",
       "      <td>14.275000</td>\n",
       "      <td>3.217222</td>\n",
       "      <td>3.172222</td>\n",
       "      <td>1114</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>net sale</td>\n",
       "      <td>4.636471</td>\n",
       "      <td>14.233750</td>\n",
       "      <td>4.378889</td>\n",
       "      <td>6.326111</td>\n",
       "      <td>1701</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>xbrl taxonomy extension</td>\n",
       "      <td>4.751176</td>\n",
       "      <td>14.245000</td>\n",
       "      <td>4.487222</td>\n",
       "      <td>6.331111</td>\n",
       "      <td>582</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>xbrl taxonomy</td>\n",
       "      <td>4.751176</td>\n",
       "      <td>14.245000</td>\n",
       "      <td>4.487222</td>\n",
       "      <td>6.331111</td>\n",
       "      <td>589</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>sale volume</td>\n",
       "      <td>4.435625</td>\n",
       "      <td>14.694286</td>\n",
       "      <td>3.942778</td>\n",
       "      <td>5.714444</td>\n",
       "      <td>505</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>taxonomy extension</td>\n",
       "      <td>4.751176</td>\n",
       "      <td>14.245000</td>\n",
       "      <td>4.487222</td>\n",
       "      <td>6.331111</td>\n",
       "      <td>844</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>first nine</td>\n",
       "      <td>4.349231</td>\n",
       "      <td>13.920000</td>\n",
       "      <td>3.141111</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>632</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>company belief</td>\n",
       "      <td>4.634286</td>\n",
       "      <td>13.568333</td>\n",
       "      <td>3.604444</td>\n",
       "      <td>4.522778</td>\n",
       "      <td>542</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>june company</td>\n",
       "      <td>4.681176</td>\n",
       "      <td>13.365556</td>\n",
       "      <td>4.421111</td>\n",
       "      <td>6.682778</td>\n",
       "      <td>505</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        word  good_score  bad_score  good_score_all  \\\n",
       "154             raw material    4.558000  14.990000        3.798333   \n",
       "125             net earnings    4.454615  14.275000        3.217222   \n",
       "131                 net sale    4.636471  14.233750        4.378889   \n",
       "197  xbrl taxonomy extension    4.751176  14.245000        4.487222   \n",
       "196            xbrl taxonomy    4.751176  14.245000        4.487222   \n",
       "170              sale volume    4.435625  14.694286        3.942778   \n",
       "187       taxonomy extension    4.751176  14.245000        4.487222   \n",
       "67                first nine    4.349231  13.920000        3.141111   \n",
       "18            company belief    4.634286  13.568333        3.604444   \n",
       "96              june company    4.681176  13.365556        4.421111   \n",
       "\n",
       "     bad_score_all  count  good_nums  bad_nums  diff  \n",
       "154       3.331111    801         15         4    11  \n",
       "125       3.172222   1114         13         4     9  \n",
       "131       6.326111   1701         17         8     9  \n",
       "197       6.331111    582         17         8     9  \n",
       "196       6.331111    589         17         8     9  \n",
       "170       5.714444    505         16         7     9  \n",
       "187       6.331111    844         17         8     9  \n",
       "67        3.866667    632         13         5     8  \n",
       "18        4.522778    542         14         6     8  \n",
       "96        6.682778    505         17         9     8  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodvbad_path = os.path.join(\"data\", \"goodvbad\")\n",
    "if not os.path.isdir(goodvbad_path):\n",
    "    os.mkdir(goodvbad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.round(2).to_csv(\"data/goodvbad/{}_{}_{}_n{}-{}.csv\".format(sector[:8], score_type[:3], alpha, n_min, n_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove all the previous files earlier than 2020\n",
    "for cik in tqdm(bad_cik):\n",
    "    tenk_path = os.path.join(\"data\", \"10k\", cik, \"rawtext\")\n",
    "    all_raws = os.listdir(tenk_path)\n",
    "    for filename in all_raws:\n",
    "        if filename[0] == '.':\n",
    "            continue\n",
    "        year = int(filename.split('_')[1].split('-')[0])\n",
    "        # print(year)\n",
    "        if year < 2020:\n",
    "            # print(os.path.join(tenk_path, filename))\n",
    "            os.remove(os.path.join(tenk_path, filename))\n",
    "    \n",
    "    tenq_path = os.path.join(\"data\", \"10q\", cik, \"rawtext\")\n",
    "    all_raws = os.listdir(tenq_path)\n",
    "    for filename in all_raws:\n",
    "        if filename[0] == '.':\n",
    "            continue\n",
    "        year = int(filename.split('_')[1].split('-')[0])\n",
    "        # print(year)\n",
    "        if year < 2020:\n",
    "            # print(os.path.join(tenk_path, filename))\n",
    "            os.remove(os.path.join(tenq_path, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the previous incompleted scraping\n",
    "dirname = os.path.join(\"data\", \"10q\")\n",
    "all_files = os.listdir(dirname)\n",
    "\n",
    "import shutil\n",
    "for filename in all_files:\n",
    "    pkldir = os.path.join(dirname, filename, \"pickle\")\n",
    "    if os.path.isdir(pkldir):\n",
    "        if not os.path.exists(os.path.join(pkldir, \"agg_texts.pkl\")):\n",
    "            shutil.rmtree(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"energy_good_vs_bad_uni_bi_tri.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accompanying note consolidated</td>\n",
       "      <td>9.773333</td>\n",
       "      <td>23.7600</td>\n",
       "      <td>4.886667</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accompanying note integral</td>\n",
       "      <td>10.557500</td>\n",
       "      <td>21.6950</td>\n",
       "      <td>7.038333</td>\n",
       "      <td>7.231667</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acmp</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.9800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.663333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>activity cash flow</td>\n",
       "      <td>10.975000</td>\n",
       "      <td>21.0660</td>\n",
       "      <td>7.316667</td>\n",
       "      <td>17.555000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusted ebitda</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.2825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.855000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             word  good_score  bad_score  good_score_all  \\\n",
       "0  accompanying note consolidated    9.773333    23.7600        4.886667   \n",
       "1      accompanying note integral   10.557500    21.6950        7.038333   \n",
       "2                            acmp    0.000000    21.9800        0.000000   \n",
       "3              activity cash flow   10.975000    21.0660        7.316667   \n",
       "4                 adjusted ebitda    0.000000    22.2825        0.000000   \n",
       "\n",
       "   bad_score_all  good_nums  bad_nums  diff  \n",
       "0       3.960000          3         1     2  \n",
       "1       7.231667          4         2     2  \n",
       "2       3.663333          0         1     1  \n",
       "3      17.555000          4         5     1  \n",
       "4      14.855000          0         4     4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.read_csv(\"data/sp500_component_stocks.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79    Citigroup Inc.\n",
       "Name: Agilent Technologies Inc., dtype: object"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp[comp['A'] == \"C\"][\"Agilent Technologies Inc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44                   Apache Corporation\n",
       "111         Cabot Oil & Gas Corporation\n",
       "128                 Chevron Corporation\n",
       "163                  EOG Resources Inc.\n",
       "322            Marathon Oil Corporation\n",
       "358    Occidental Petroleum Corporation\n",
       "Name: Agilent Technologies Inc., dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp[comp['A'].isin(good_companies)][\"Agilent Technologies Inc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215            Halliburton Company\n",
       "274      Kinder Morgan Inc Class P\n",
       "343    National Oilwell Varco Inc.\n",
       "354                     ONEOK Inc.\n",
       "411                Schlumberger NV\n",
       "487        Williams Companies Inc.\n",
       "Name: Agilent Technologies Inc., dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp[comp['A'].isin(bad_companies)][\"Agilent Technologies Inc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cik(ticker):\n",
    "    \"\"\" Get the cik for the ticker specified by the input argument \n",
    "    Input:\n",
    "        ticker(str): ticker of the company e.g. \"FB\"\n",
    "    \"\"\"\n",
    "    return ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ciks(tickers):\n",
    "    ciks = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        ciks.append(get_cik(ticker))\n",
    "\n",
    "    return ciks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(s, n):\n",
    "    \"\"\" Get all the n-gram for input texts s\n",
    "    Input:\n",
    "        s (str): A string of texts with each word separated by a whitespace\n",
    "        n (int): n-gram to extract\n",
    "    Return:\n",
    "        [str]: A list of string in the following format ([['a', 'b'], ['b', 'c'], ['c', 'd']])\n",
    "    \"\"\"\n",
    "    \n",
    "    s = s.split(' ')\n",
    "    output = []\n",
    "    for i in range(len(s) - n + 1):\n",
    "        output.append(s[i:i+n])\n",
    "\n",
    "    return output\n",
    "\n",
    "# ngrams('a b c d', 2) # [['a', 'b'], ['b', 'c'], ['c', 'd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(doc, df_dict, n_min, n_max):\n",
    "    \"\"\" Count the number of good and bad words occurred in the document\n",
    "    Input:\n",
    "        doc (str): A string with all the words in the documents\n",
    "        df_dict (pd.DataFrame): A DataFrame with word and isGood column, generated by previous section\n",
    "        n_min, n_max (int): specify the ngram range used to generate the dictionary, should be consistent with how df_dict is generated\n",
    "    Return:\n",
    "        (dict): A dictionary with value good_count and bad_count\n",
    "    \"\"\"\n",
    "    grams = []\n",
    "    for n in range(n_min, n_max + 1):\n",
    "        grams.extend([' '.join(li) for li in ngrams(doc, 2)])\n",
    "    \n",
    "    good_count = bad_count = 0\n",
    "    \n",
    "    for g in grams:\n",
    "        if g in df_dict[\"word\"].values:\n",
    "            val = df_dict[df_dict[\"word\"] == g][\"isGood\"].values\n",
    "            if val == 1:\n",
    "                good_count += 1\n",
    "            elif val == -1:\n",
    "                bad_count += 1\n",
    "\n",
    "    return {\"good_count\": good_count, \"bad_count\": bad_count}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(df_topk, val_tickers, dict_threshold):\n",
    "    \"\"\" Perform the validation step\n",
    "    The validation rationale: Companies whose score are in upper 50% group are considered \"bad\" companies and the corresponding val_true = 1; 0 otherwise (in lower 50% group, which is considered a good company)\n",
    "    Input:\n",
    "        df_topk (pd.DataFrame): containes the sector specific dict\n",
    "        val_tickers (list): A list of tickers to be validated\n",
    "        dict_threshold (int): A gram is considered as a good word if its good_nums - bad_nums > threshold\n",
    "        val_true (list): A list of true labels for each companies\n",
    "    \"\"\"\n",
    "    diff = df_topk[\"good_nums\"] - df_topk[\"bad_nums\"]\n",
    "    df_topk[\"isGood\"] = diff.apply(lambda x: 1 if x > dict_threshold else (\n",
    "        -1 if x < -dict_threshold else 0))\n",
    "\n",
    "    # 1 if good_nums - bad_nums > threshold; -1 if good_nums - bad_nums < -threshold; 0 otherwise\n",
    "    val_ciks = [get_cik(ticker) for ticker in val_tickers]\n",
    "    \n",
    "    ret_texts = get_texts(val_ciks, val_tickers) \n",
    "\n",
    "    val_pred = []\n",
    "    for doc in tqdm(ret_texts[\"docs\"]):\n",
    "        ret = get_count(doc, df_topk[[\"word\", \"isGood\"]], 2, 3)\n",
    "\n",
    "        if ret[\"good_count\"] - ret[\"bad_count\"] > 0:\n",
    "            val_pred.append(1)\n",
    "        else:\n",
    "            val_pred.append(0)\n",
    "    \n",
    "    print(\"val_pred: {}\".format(val_pred))\n",
    "    \n",
    "    return val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LEG', 'F', 'AMZN', 'GM', 'TSLA', 'NCLH', 'MGM', 'WYNN', 'DPZ',\n",
       "       'DRI', 'EXPE', 'CMG', 'CCL', 'MCD', 'MAR', 'YUM', 'SBUX', 'ROL'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tickers = ['NOV', 'OKE', 'HAL', 'SLB', 'WMB', 'KMI']\n",
    "tickers = list(good_companies) + list(bad_companies)\n",
    "ciks = [get_cik(ticker) for ticker in tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:01, 20.41it/s]\n"
     ]
    }
   ],
   "source": [
    "ret = get_texts(ciks, tickers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_true = [1 for _ in good_companies] + [0 for _ in bad_companies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"good_nums\"] > df[\"bad_nums\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:01, 18.25it/s]\n",
      "100%|██████████| 36/36 [04:39<00:00,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_pred: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_pred = validation(df, tickers, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 2 16]\n",
      " [ 0 18]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(val_true, val_pred)\n",
    "print(\"Confusion Matrix: \\n{}\".format(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddddf = pd.read_csv(\"data/goodvbad/env_0.333_n2-3.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>commodity price</td>\n",
       "      <td>1.02</td>\n",
       "      <td>12.82</td>\n",
       "      <td>0.18</td>\n",
       "      <td>9.77</td>\n",
       "      <td>2794</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>natural gas</td>\n",
       "      <td>0.90</td>\n",
       "      <td>13.53</td>\n",
       "      <td>0.09</td>\n",
       "      <td>8.25</td>\n",
       "      <td>17304</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>plant equipment</td>\n",
       "      <td>0.90</td>\n",
       "      <td>12.54</td>\n",
       "      <td>0.23</td>\n",
       "      <td>9.08</td>\n",
       "      <td>2256</td>\n",
       "      <td>27</td>\n",
       "      <td>76</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>sale volume</td>\n",
       "      <td>1.06</td>\n",
       "      <td>12.87</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8.70</td>\n",
       "      <td>3060</td>\n",
       "      <td>27</td>\n",
       "      <td>71</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>raw material</td>\n",
       "      <td>0.79</td>\n",
       "      <td>11.59</td>\n",
       "      <td>0.26</td>\n",
       "      <td>8.61</td>\n",
       "      <td>3464</td>\n",
       "      <td>35</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  good_score  bad_score  good_score_all  bad_score_all  \\\n",
       "20   commodity price        1.02      12.82            0.18           9.77   \n",
       "118      natural gas        0.90      13.53            0.09           8.25   \n",
       "150  plant equipment        0.90      12.54            0.23           9.08   \n",
       "180      sale volume        1.06      12.87            0.28           8.70   \n",
       "161     raw material        0.79      11.59            0.26           8.61   \n",
       "\n",
       "     count  good_nums  bad_nums  diff  \n",
       "20    2794         18        80    62  \n",
       "118  17304         10        64    54  \n",
       "150   2256         27        76    49  \n",
       "180   3060         27        71    44  \n",
       "161   3464         35        78    43  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 98\n"
     ]
    }
   ],
   "source": [
    "num_good = (ddddf[\"good_nums\"] > ddddf[\"bad_nums\"]).sum()\n",
    "num_bad = (ddddf[\"good_nums\"] < ddddf[\"bad_nums\"]).sum()\n",
    "print(num_good, num_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10878 11231\n"
     ]
    }
   ],
   "source": [
    "total_num_good = ddddf[\"good_nums\"].sum()\n",
    "total_num_bad = ddddf[\"bad_nums\"].sum()\n",
    "print(total_num_good, total_num_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_threshold = 1\n",
    "diff = df[\"good_nums\"] - df[\"bad_nums\"]\n",
    "df[\"isGood\"] = diff.apply(lambda x: 1 if x > dict_threshold else (\n",
    "    -1 if x < -dict_threshold else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>isGood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accompanying note consolidated</td>\n",
       "      <td>13.830</td>\n",
       "      <td>21.886667</td>\n",
       "      <td>2.305000</td>\n",
       "      <td>10.943333</td>\n",
       "      <td>1143</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accompanying note integral</td>\n",
       "      <td>10.545</td>\n",
       "      <td>21.705000</td>\n",
       "      <td>3.515000</td>\n",
       "      <td>14.470000</td>\n",
       "      <td>1584</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adjusted ebitda</td>\n",
       "      <td>10.975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.316667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1051</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adopted pursuant</td>\n",
       "      <td>9.294</td>\n",
       "      <td>21.880000</td>\n",
       "      <td>7.745000</td>\n",
       "      <td>7.293333</td>\n",
       "      <td>1043</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adopted pursuant section</td>\n",
       "      <td>9.294</td>\n",
       "      <td>21.880000</td>\n",
       "      <td>7.745000</td>\n",
       "      <td>7.293333</td>\n",
       "      <td>1037</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             word  good_score  bad_score  good_score_all  \\\n",
       "0  accompanying note consolidated      13.830  21.886667        2.305000   \n",
       "1      accompanying note integral      10.545  21.705000        3.515000   \n",
       "2                 adjusted ebitda      10.975   0.000000        7.316667   \n",
       "3                adopted pursuant       9.294  21.880000        7.745000   \n",
       "4        adopted pursuant section       9.294  21.880000        7.745000   \n",
       "\n",
       "   bad_score_all  count  good_nums  bad_nums  isGood  \n",
       "0      10.943333   1143          1         3      -1  \n",
       "1      14.470000   1584          2         4      -1  \n",
       "2       0.000000   1051          4         0       1  \n",
       "3       7.293333   1043          5         2       1  \n",
       "4       7.293333   1037          5         2       1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>isGood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accompanying note consolidated</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accompanying note integral</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adjusted ebitda</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adopted pursuant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adopted pursuant section</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>trustee filed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>unconsolidated affiliate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>well incident</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>williams company</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>williams partner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               word  isGood\n",
       "0    accompanying note consolidated      -1\n",
       "1        accompanying note integral      -1\n",
       "2                   adjusted ebitda       1\n",
       "3                  adopted pursuant       1\n",
       "4          adopted pursuant section       1\n",
       "..                              ...     ...\n",
       "195                   trustee filed       0\n",
       "196        unconsolidated affiliate       1\n",
       "197                   well incident       0\n",
       "198                williams company       0\n",
       "199                williams partner       1\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"word\", \"isGood\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate N-grams based on sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = \"Energy\"\n",
    "# sector = \"Energy\"\n",
    "\n",
    "# score_type = \"governanceScore\"\n",
    "score_type = \"environmentScore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = ['Consumer Cyclical', 'Technology', 'Financial Services']\n",
    "score_types = [\"governanceScore\", \"environmentScore\", \"socialScore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_listed = [\"BBWI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/n_grams/Technology_environmentScore.pkl', 'rb') as handle:\n",
    "    feature_names = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accrued unpaid',\n",
       " 'acquired intangible',\n",
       " 'additional information regarding',\n",
       " 'adopted pursuant',\n",
       " 'adopted pursuant section',\n",
       " 'affect financial result',\n",
       " 'allowance credit',\n",
       " 'amortized cost',\n",
       " 'amount senior',\n",
       " 'annual report year',\n",
       " 'average price',\n",
       " 'average selling',\n",
       " 'average selling price',\n",
       " 'benefit pension',\n",
       " 'billion billion',\n",
       " 'cash flow hedge',\n",
       " 'channel partner',\n",
       " 'class action',\n",
       " 'cloud computing',\n",
       " 'cloud license',\n",
       " 'cloud service',\n",
       " 'commercial paper',\n",
       " 'company adopted',\n",
       " 'company also',\n",
       " 'company belief',\n",
       " 'company entered',\n",
       " 'company recorded',\n",
       " 'compared fiscal',\n",
       " 'compared million',\n",
       " 'compared period',\n",
       " 'compared three',\n",
       " 'compared three month',\n",
       " 'comprehensive loss',\n",
       " 'condensed financial',\n",
       " 'condensed financial statement',\n",
       " 'consolidated condensed',\n",
       " 'consolidated condensed financial',\n",
       " 'consolidated statement income',\n",
       " 'consolidated statement operation',\n",
       " 'constant currency',\n",
       " 'contingent consideration',\n",
       " 'continuing operation',\n",
       " 'contract manufacturer',\n",
       " 'convertible debt',\n",
       " 'convertible note',\n",
       " 'corning right',\n",
       " 'cost product',\n",
       " 'currency forward',\n",
       " 'currency forward contract',\n",
       " 'data center',\n",
       " 'december company',\n",
       " 'deferred revenue',\n",
       " 'defined benefit',\n",
       " 'defined benefit pension',\n",
       " 'designated hedging',\n",
       " 'diluted net',\n",
       " 'diluted net income',\n",
       " 'district court',\n",
       " 'due primarily',\n",
       " 'effect result financial',\n",
       " 'end customer',\n",
       " 'ended april',\n",
       " 'ended august',\n",
       " 'ended february',\n",
       " 'ended january',\n",
       " 'ended july',\n",
       " 'ended may',\n",
       " 'ended october',\n",
       " 'enterprise company',\n",
       " 'equity incentive',\n",
       " 'equivalent marketable',\n",
       " 'exhibit filed',\n",
       " 'expense current',\n",
       " 'fair value derivative',\n",
       " 'fasb issued asu',\n",
       " 'financial measure',\n",
       " 'financial statement additional',\n",
       " 'financial statement item',\n",
       " 'financing receivables',\n",
       " 'first nine',\n",
       " 'first nine month',\n",
       " 'first six',\n",
       " 'first six month',\n",
       " 'fiscal company',\n",
       " 'fiscal compared',\n",
       " 'fiscal fiscal',\n",
       " 'fiscal primarily',\n",
       " 'fiscal primarily due',\n",
       " 'fiscal quarter ended',\n",
       " 'flow hedge',\n",
       " 'following provides',\n",
       " 'foreign currency forward',\n",
       " 'free cash',\n",
       " 'gross profit',\n",
       " 'hardware product',\n",
       " 'hewlett packard',\n",
       " 'hewlett packard enterprise',\n",
       " 'income per',\n",
       " 'income per share',\n",
       " 'increase million',\n",
       " 'increased primarily due',\n",
       " 'integrated circuit',\n",
       " 'interest rate swap',\n",
       " 'investment portfolio',\n",
       " 'issued asu',\n",
       " 'item part',\n",
       " 'june company',\n",
       " 'june december',\n",
       " 'june june',\n",
       " 'license agreement',\n",
       " 'license support',\n",
       " 'loan credit',\n",
       " 'manufacturing process',\n",
       " 'march company',\n",
       " 'margin percentage',\n",
       " 'million aggregate',\n",
       " 'million aggregate principal',\n",
       " 'million fiscal',\n",
       " 'month ended april',\n",
       " 'month ended december',\n",
       " 'month ended february',\n",
       " 'month ended january',\n",
       " 'month ended july',\n",
       " 'month ended june',\n",
       " 'month ended march',\n",
       " 'month ended may',\n",
       " 'month ended september',\n",
       " 'month fiscal',\n",
       " 'month period',\n",
       " 'month period ended',\n",
       " 'mutual fund',\n",
       " 'net cash provided',\n",
       " 'net earnings',\n",
       " 'net income per',\n",
       " 'net revenue',\n",
       " 'net sale',\n",
       " 'nine month fiscal',\n",
       " 'note condensed',\n",
       " 'note condensed consolidated',\n",
       " 'note note consolidated',\n",
       " 'notional amount',\n",
       " 'officer pursuant',\n",
       " 'open market',\n",
       " 'open source',\n",
       " 'operating financial',\n",
       " 'operating margin',\n",
       " 'operating result financial',\n",
       " 'operating segment',\n",
       " 'oracle corporation',\n",
       " 'packard enterprise',\n",
       " 'packard enterprise company',\n",
       " 'pension plan',\n",
       " 'per common',\n",
       " 'percentage net',\n",
       " 'period fiscal',\n",
       " 'period prior',\n",
       " 'plan asset',\n",
       " 'preferred stock',\n",
       " 'principal amount senior',\n",
       " 'principal financial',\n",
       " 'privately held',\n",
       " 'product revenue',\n",
       " 'professional service',\n",
       " 'purchased intangible',\n",
       " 'quarter compared',\n",
       " 'quarter first',\n",
       " 'quarter fiscal year',\n",
       " 'rate swap',\n",
       " 'raw material',\n",
       " 'refer note',\n",
       " 'reference exhibit',\n",
       " 'remaining performance',\n",
       " 'remaining performance obligation',\n",
       " 'restricted cash',\n",
       " 'restructuring plan',\n",
       " 'revenue decreased',\n",
       " 'second quarter fiscal',\n",
       " 'segment net',\n",
       " 'semiconductor industry',\n",
       " 'senior note due',\n",
       " 'service provider',\n",
       " 'service revenue',\n",
       " 'software license',\n",
       " 'statement additional',\n",
       " 'statement income',\n",
       " 'statement item',\n",
       " 'statement operation',\n",
       " 'stock repurchase program',\n",
       " 'strategic investment',\n",
       " 'support service',\n",
       " 'term loan',\n",
       " 'term loan credit',\n",
       " 'third quarter fiscal',\n",
       " 'total revenue',\n",
       " 'unaudited condensed',\n",
       " 'unaudited condensed consolidated',\n",
       " 'unrealized loss',\n",
       " 'value derivative',\n",
       " 'year ended december',\n",
       " 'year ended june']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esg_score = pd.read_excel(\"data/esg_score.xlsx\", sheet_name = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sector in sectors:\n",
    "    for score_type in score_types:\n",
    "        esgs = df_esg_score[df_esg_score[\"sector\"] == sector][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "        score = esgs[score_type]\n",
    "        alpha = 0.3\n",
    "        upper_score = np.quantile(score, 1 - alpha)\n",
    "        lower_score = np.quantile(score, alpha)\n",
    "\n",
    "        bad_companies = list(esgs[esgs[score_type] > upper_score][\"Company\"].values)\n",
    "        good_companies = list(esgs[esgs[score_type] < lower_score][\"Company\"].values)\n",
    "\n",
    "        for t in not_listed:\n",
    "            if t in bad_companies:\n",
    "                bad_companies.remove(t)\n",
    "            if t in good_companies:\n",
    "                good_companies.remove(t)\n",
    "\n",
    "        tickers = good_companies + bad_companies\n",
    "        ciks = get_ciks(tickers)\n",
    "        ret = get_texts(ciks, tickers)\n",
    "        docs = ret[\"docs\"]\n",
    "        \n",
    "        n_min = 2\n",
    "        n_max = 3\n",
    "        cv = CountVectorizer(max_df=0.7, stop_words=stop_words, max_features=200, ngram_range=(n_min, n_max))\n",
    "        word_count_vector = cv.fit_transform(docs)\n",
    "        feature_names = cv.get_feature_names()\n",
    "\n",
    "        with open('data/n_grams/{}_{}.pkl'.format(sector, score_type), 'wb') as handle:\n",
    "            pickle.dump(feature_names, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/n_grams/{}_{}.pkl'.format(sector, score_type), 'wb') as handle:\n",
    "    pickle.dump(feature_names, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = df_esg_score[df_esg_score[\"sector\"] == sector][\"Company\"]\n",
    "esgs = df_esg_score[df_esg_score[\"sector\"] == sector][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "ciks = get_ciks(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:05,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "ret = get_texts(ciks, tickers)\n",
    "docs = ret[\"docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# TODO: Modify here for different ngram range\n",
    "n_min = 2\n",
    "n_max = 3\n",
    "cv = CountVectorizer(max_df=0.6, stop_words=stop_words, max_features=200, ngram_range=(n_min, n_max))\n",
    "word_count_vector = cv.fit_transform(docs)\n",
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"combination\": [], \"bad_tickers\": [], \"good_tickers\": []}\n",
    "\n",
    "for sec in df_esg_score[\"sector\"].dropna().unique():\n",
    "    for s_type in [\"governanceScore\", \"environmentScore\", \"socialScore\"]:\n",
    "        tickers = df_esg_score[df_esg_score[\"sector\"] == sec][\"Company\"]\n",
    "        esgs = df_esg_score[df_esg_score[\"sector\"] == sec][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "        score = esgs[s_type]\n",
    "        alpha = 0.25\n",
    "        upper_score = np.quantile(score, 1 - alpha)\n",
    "        lower_score = np.quantile(score, alpha)\n",
    "\n",
    "        bad_companies = esgs[esgs[s_type] > upper_score][\"Company\"].values\n",
    "        good_companies = esgs[esgs[s_type] < lower_score][\"Company\"].values\n",
    "\n",
    "        # print(sec)\n",
    "        d[\"combination\"].append(sec + \"_\" + s_type)\n",
    "        d[\"good_tickers\"].append(','.join(good_companies))\n",
    "        d[\"bad_tickers\"].append(','.join(bad_companies))\n",
    "\n",
    "ddf = pd.DataFrame(data=d)\n",
    "ddf.to_csv(\"data/goodvbad/goodcbad_companies.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcf325ffca4e7352bcfac699b7999bb028ddd94d8390136137b75043a4ee01b0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
