import pandas as pd
import os
import tqdm
from sklearn.metrics import confusion_matrix 

ticker_library = pd.read_csv(os.path.join("data", "tickers.csv"))

def get_cik(ticker):
    """ Get the cik for the ticker specified by the input argument 
    Input:
        ticker(str): ticker of the company e.g. "FB"
    """
    return ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:]
    
def ngrams(s, n):
    """ Get all the n-gram for input texts s
    Input:
        s (str): A string of texts with each word separated by a whitespace
        n (int): n-gram to extract
    Return:
        [str]: A list of string in the following format ([['a', 'b'], ['b', 'c'], ['c', 'd']])
    """
    
    s = s.split(' ')
    output = []
    for i in range(len(s) - n + 1):
        output.append(s[i:i+n])

    return output

def get_count(doc, df_dict, n_min, n_max):
    """ Count the number of good and bad words occurred in the document
    Input:
        doc (str): A string with all the words in the documents
        df_dict (pd.DataFrame): A DataFrame with word and isGood column, generated by previous section
        n_min, n_max (int): specify the ngram range used to generate the dictionary, should be consistent with how df_dict is generated
    Return:
        (dict): A dictionary with value good_count and bad_count
    """
    grams = []
    for n in range(n_min, n_max + 1):
        grams.extend([' '.join(li) for li in ngrams(doc, 2)])
    
    good_count = bad_count = 0
    
    for g in grams:
        if g in df_dict["word"].values:
            val = df_dict[df_dict["word"] == g]["isGood"].values
            if val == 1:
                good_count += 1
            elif val == -1:
                bad_count += 1

    return {"good_count": good_count, "bad_count": bad_count}
    
def validation(df_topk, val_tickers, dict_threshold):
    """ Perform the validation step
    The validation rationale: Companies whose score are in upper 50% group are considered "bad" companies and the corresponding val_true = 1; 0 otherwise (in lower 50% group, which is considered a good company)
    Input:
        df_topk (pd.DataFrame): containes the sector specific dict
        val_tickers (list): A list of tickers to be validated
        dict_threshold (int): A gram is considered as a good word if its good_nums - bad_nums > threshold
    """
    diff = df_topk["good_nums"] - df_topk["bad_nums"]
    df_topk["isGood"] = diff.apply(lambda x: 1 if x > dict_threshold else (
        -1 if x < -dict_threshold else 0))

    # 1 if good_nums - bad_nums > threshold; -1 if good_nums - bad_nums < -threshold; 0 otherwise
    val_ciks = [get_cik(ticker) for ticker in val_tickers]
    
    ret_texts = get_texts(val_ciks, val_tickers) 

    val_pred = []
    for doc in tqdm(ret_texts["docs"]):
        ret = get_count(doc, df_topk[["word", "isGood"]], 2, 3)

        if ret["good_count"] - ret["bad_count"] > 0:
            val_pred.append(1)
        else:
            val_pred.append(0)
    
    print("val_pred: {}".format(val_pred))
    
    return val_pred


# TODO: Update to the actual tickers to test
val_tickers = ["FB", "GOOG"] # should be a list of tickers you split into test set

val_ciks = [get_cik(ticker) for ticker in val_tickers]

val_pred = validation(df, val_tickers, 2)   # df is the dictionary with good_num, bad_num, diff

# val_true (list): A list of true labels for each companies (1 for good company, 0 for bad)
val_true = [1, 1]
cm = confusion_matrix(val_true, val_pred)
print("Confusion Matrix: \n{}".format(cm))
