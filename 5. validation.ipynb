{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/luckywang/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import linregress\n",
    "from utils.preprocessing import get_texts\n",
    "from utils.preprocessing import get_texts, stop_words\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esg_score = pd.read_excel(\"data/esg_score.xlsx\", sheet_name = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_tickers = ticker_library[\"ticker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esg_score = df_esg_score[df_esg_score[\"Company\"].isin(legit_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_esg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modify here for different sectors and score_types\n",
    "# set the sector and ESG type for the analysis\n",
    "sector = \"Financial Services\"\n",
    "# sector = \"Energy\"\n",
    "\n",
    "score_type = \"governanceScore\"\n",
    "# score_type = \"environmentScore\"\n",
    "# score_type = \"socialScore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set\n",
    "train_bad=random.sample(list(bad_companies), int(len(bad_companies)*0.7))\n",
    "train_good=random.sample(list(good_companies), int(len(good_companies)*0.7))\n",
    "\n",
    "#validation set\n",
    "validate_bad = [i for i in bad_companies if i not in train_bad]\n",
    "validate_good = [i for i in good_companies if i not in train_good]\n",
    "\n",
    "# validate_good = pd.DataFrame(validate_good) \n",
    "# validate_bad = pd.DataFrame(validate_bad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.DataFrame({'good':validate_good, 'bad':validate_bad})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the list of good and bad companies\n",
    "validation_path = os.path.join(\"data\", \"validation_data\")\n",
    "if not os.path.isdir(validation_path):\n",
    "    os.mkdir(validation_path)\n",
    "\n",
    "validation.to_csv(\"data/validation_data/{}_{}_{}.csv\".format(sector[:8], score_type[:3], alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(train_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(validate_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esgs[esgs[score_type] > upper_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data bad companies scores\n",
    "train_bad_scores=pd.DataFrame()\n",
    "for i in train_bad:\n",
    "    df_bad=esgs[esgs['Company'] == i]\n",
    "    train_bad_scores=train_bad_scores.append(df_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data good companies scores\n",
    "train_good_scores=pd.DataFrame()\n",
    "\n",
    "for i in train_good:\n",
    "    df_good=esgs[esgs['Company'] == i]\n",
    "    train_good_scores =train_good_scores.append(df_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_companies_score = esgs[esgs[score_type] > upper_score][score_type].values\n",
    "# good_companies_score = esgs[esgs[score_type] < lower_score][score_type].values\n",
    "\n",
    "good_companies_score_training=train_good_scores[score_type]\n",
    "bad_companies_score_training=train_bad_scores[score_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.138499999999999 6.109999999999999\n"
     ]
    }
   ],
   "source": [
    "avg_bad = np.mean(bad_companies_score_training)\n",
    "avg_good = np.mean(good_companies_score_training)\n",
    "print(avg_bad, avg_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.23 10.23\n"
     ]
    }
   ],
   "source": [
    "print(upper_score, lower_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohammed Al Harmoudi\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))\n",
    "good_cik = []\n",
    "bad_cik = []\n",
    "for ticker in train_good:    \n",
    "    try:\n",
    "        # for a given ticker, find its cik number through th ticker library\n",
    "        good_cik.append(ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:])\n",
    "    except:\n",
    "        # if could not find cik, give it a empty cik\n",
    "        good_cik.append('')\n",
    "\n",
    "for ticker in train_bad:    \n",
    "    try:\n",
    "        # for a given ticker, find its cik number through th ticker library\n",
    "        bad_cik.append(ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:])\n",
    "    except:\n",
    "        # if could not find cik, give it a empty cik\n",
    "        bad_cik.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret_good = get_texts(good_cik, train_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret_bad = get_texts(bad_cik, train_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_docs = ret_good[\"docs\"]\n",
    "bad_docs = ret_bad[\"docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohammed Al Harmoudi\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# TODO: Modify here for different ngram range\n",
    "n_min = 2\n",
    "n_max = 3\n",
    "cv = CountVectorizer(max_df=0.7, stop_words=stop_words, max_features=200, ngram_range=(n_min, n_max))\n",
    "word_count_vector = cv.fit_transform(good_docs + bad_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_feature = word_count_vector.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"word\": [], \"good_score\": [], \"bad_score\": [], \"good_score_all\": []\n",
    "    , \"bad_score_all\": [], \"count\": [], \"good_nums\": [], \"bad_nums\": []}\n",
    "\n",
    "for feature_idx, word in enumerate(feature_names):\n",
    "    good_sum = bad_sum = good_num = bad_num = 0\n",
    "\n",
    "    for i, doc_set in enumerate(good_docs):\n",
    "        if word in doc_set:\n",
    "            good_num += 1\n",
    "            good_sum += good_companies_score[i]\n",
    "    for i, doc_set in enumerate(bad_docs):\n",
    "        if word in doc_set:\n",
    "            bad_num += 1\n",
    "            bad_sum += bad_companies_score[i]\n",
    "    \n",
    "    # print(\"word: {}\".format(word))\n",
    "    d[\"word\"].append(word) \n",
    "    \n",
    "    if good_num:\n",
    "        d[\"good_score\"].append(good_sum / good_num)\n",
    "    else:\n",
    "        d[\"good_score\"].append(0)\n",
    "    if bad_num:\n",
    "        d[\"bad_score\"].append(bad_sum / bad_num)\n",
    "    else:\n",
    "        d[\"bad_score\"].append(0)\n",
    "\n",
    "    d[\"good_score_all\"].append(good_sum / len(good_docs))\n",
    "    d[\"bad_score_all\"].append(bad_sum / len(bad_docs))\n",
    "\n",
    "    d[\"count\"].append(count_feature[feature_idx])\n",
    "    d[\"good_nums\"].append(good_num)\n",
    "    d[\"bad_nums\"].append(bad_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accident year</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>7.668571</td>\n",
       "      <td>0.066364</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>2329</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accompanying note</td>\n",
       "      <td>1.002308</td>\n",
       "      <td>7.452308</td>\n",
       "      <td>0.592273</td>\n",
       "      <td>4.403636</td>\n",
       "      <td>847</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acquisition cost</td>\n",
       "      <td>0.867273</td>\n",
       "      <td>7.795625</td>\n",
       "      <td>0.433636</td>\n",
       "      <td>5.669545</td>\n",
       "      <td>1249</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adjusted earnings</td>\n",
       "      <td>1.016667</td>\n",
       "      <td>6.565000</td>\n",
       "      <td>0.138636</td>\n",
       "      <td>0.596818</td>\n",
       "      <td>918</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusted operating</td>\n",
       "      <td>1.042857</td>\n",
       "      <td>5.356000</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>1.217273</td>\n",
       "      <td>1454</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adjustment expense</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>7.531111</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>3.080909</td>\n",
       "      <td>1133</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aflac japan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266818</td>\n",
       "      <td>732</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allowance loan</td>\n",
       "      <td>0.835833</td>\n",
       "      <td>8.014615</td>\n",
       "      <td>0.455909</td>\n",
       "      <td>4.735909</td>\n",
       "      <td>951</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amount except</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>9.350000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>779</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>available sale</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>7.723077</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>4.563636</td>\n",
       "      <td>871</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average total</td>\n",
       "      <td>0.822727</td>\n",
       "      <td>7.626000</td>\n",
       "      <td>0.411364</td>\n",
       "      <td>3.466364</td>\n",
       "      <td>885</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bank holding</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8.168889</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>3.341818</td>\n",
       "      <td>991</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bank holding company</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8.168889</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>3.341818</td>\n",
       "      <td>721</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>basel iii</td>\n",
       "      <td>0.779000</td>\n",
       "      <td>8.810000</td>\n",
       "      <td>0.354091</td>\n",
       "      <td>3.203636</td>\n",
       "      <td>1114</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>business segment</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>7.655000</td>\n",
       "      <td>0.658636</td>\n",
       "      <td>5.567273</td>\n",
       "      <td>1263</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>capital gain</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>7.287000</td>\n",
       "      <td>0.192273</td>\n",
       "      <td>3.312273</td>\n",
       "      <td>997</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>capital ratio</td>\n",
       "      <td>0.839167</td>\n",
       "      <td>7.992500</td>\n",
       "      <td>0.457727</td>\n",
       "      <td>5.812727</td>\n",
       "      <td>1804</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>card loan</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>8.464000</td>\n",
       "      <td>0.207273</td>\n",
       "      <td>1.923636</td>\n",
       "      <td>751</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>card member</td>\n",
       "      <td>1.003333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1435</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cash collateral</td>\n",
       "      <td>0.915625</td>\n",
       "      <td>8.488571</td>\n",
       "      <td>0.665909</td>\n",
       "      <td>5.401818</td>\n",
       "      <td>957</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word  good_score  bad_score  good_score_all  \\\n",
       "0          accident year    0.730000   7.668571        0.066364   \n",
       "1      accompanying note    1.002308   7.452308        0.592273   \n",
       "2       acquisition cost    0.867273   7.795625        0.433636   \n",
       "3      adjusted earnings    1.016667   6.565000        0.138636   \n",
       "4     adjusted operating    1.042857   5.356000        0.331818   \n",
       "5     adjustment expense    0.925000   7.531111        0.168182   \n",
       "6            aflac japan    0.000000   5.870000        0.000000   \n",
       "7         allowance loan    0.835833   8.014615        0.455909   \n",
       "8          amount except    0.616000   9.350000        0.140000   \n",
       "9         available sale    0.760000   7.723077        0.345455   \n",
       "10         average total    0.822727   7.626000        0.411364   \n",
       "11          bank holding    0.800000   8.168889        0.436364   \n",
       "12  bank holding company    0.800000   8.168889        0.436364   \n",
       "13             basel iii    0.779000   8.810000        0.354091   \n",
       "14      business segment    0.966000   7.655000        0.658636   \n",
       "15          capital gain    0.846000   7.287000        0.192273   \n",
       "16         capital ratio    0.839167   7.992500        0.457727   \n",
       "17             card loan    0.912000   8.464000        0.207273   \n",
       "18           card member    1.003333   0.000000        0.136818   \n",
       "19       cash collateral    0.915625   8.488571        0.665909   \n",
       "\n",
       "    bad_score_all  count  good_nums  bad_nums  \n",
       "0        2.440000   2329          2         7  \n",
       "1        4.403636    847         13        13  \n",
       "2        5.669545   1249         11        16  \n",
       "3        0.596818    918          3         2  \n",
       "4        1.217273   1454          7         5  \n",
       "5        3.080909   1133          4         9  \n",
       "6        0.266818    732          0         1  \n",
       "7        4.735909    951         12        13  \n",
       "8        2.125000    779          5         5  \n",
       "9        4.563636    871         10        13  \n",
       "10       3.466364    885         11        10  \n",
       "11       3.341818    991         12         9  \n",
       "12       3.341818    721         12         9  \n",
       "13       3.203636   1114         10         8  \n",
       "14       5.567273   1263         15        16  \n",
       "15       3.312273    997          5        10  \n",
       "16       5.812727   1804         12        16  \n",
       "17       1.923636    751          5         5  \n",
       "18       0.000000   1435          3         0  \n",
       "19       5.401818    957         16        14  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diff\"] = abs(df[\"good_nums\"] - df[\"bad_nums\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"diff\", ascending=False)#.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>insurance subsidiary</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>7.593846</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>4.487273</td>\n",
       "      <td>1246</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>net interest income</td>\n",
       "      <td>0.798667</td>\n",
       "      <td>7.905000</td>\n",
       "      <td>0.544545</td>\n",
       "      <td>2.155909</td>\n",
       "      <td>2101</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>line business</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>7.474444</td>\n",
       "      <td>0.423182</td>\n",
       "      <td>6.115455</td>\n",
       "      <td>1069</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>net revenue</td>\n",
       "      <td>0.900625</td>\n",
       "      <td>7.540000</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>2.741818</td>\n",
       "      <td>867</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>loss ratio</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>7.850833</td>\n",
       "      <td>0.173636</td>\n",
       "      <td>4.282273</td>\n",
       "      <td>846</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>mortgage loan</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>8.332222</td>\n",
       "      <td>0.359545</td>\n",
       "      <td>6.817273</td>\n",
       "      <td>4022</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>future policy</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>7.480000</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>1214</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>policy benefit</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>7.610833</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>4.151364</td>\n",
       "      <td>1121</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>insurance product</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>7.723125</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>5.616818</td>\n",
       "      <td>1022</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>invested asset</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>8.008333</td>\n",
       "      <td>0.185455</td>\n",
       "      <td>4.368182</td>\n",
       "      <td>856</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>investment gain</td>\n",
       "      <td>1.024444</td>\n",
       "      <td>7.718125</td>\n",
       "      <td>0.419091</td>\n",
       "      <td>5.613182</td>\n",
       "      <td>2750</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>investment income</td>\n",
       "      <td>0.986364</td>\n",
       "      <td>7.550556</td>\n",
       "      <td>0.493182</td>\n",
       "      <td>6.177727</td>\n",
       "      <td>3193</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>loss loss</td>\n",
       "      <td>0.946364</td>\n",
       "      <td>7.098235</td>\n",
       "      <td>0.473182</td>\n",
       "      <td>5.485000</td>\n",
       "      <td>2167</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>insurance policy</td>\n",
       "      <td>0.989091</td>\n",
       "      <td>7.157059</td>\n",
       "      <td>0.494545</td>\n",
       "      <td>5.530455</td>\n",
       "      <td>861</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>expense ratio</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>3.990909</td>\n",
       "      <td>719</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>joint venture</td>\n",
       "      <td>0.923750</td>\n",
       "      <td>6.837000</td>\n",
       "      <td>0.671818</td>\n",
       "      <td>3.107727</td>\n",
       "      <td>743</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>loan receivables</td>\n",
       "      <td>0.704286</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>0.224091</td>\n",
       "      <td>0.266818</td>\n",
       "      <td>1129</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>following set</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>7.024444</td>\n",
       "      <td>0.553636</td>\n",
       "      <td>2.873636</td>\n",
       "      <td>849</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>million second</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>7.448333</td>\n",
       "      <td>0.484091</td>\n",
       "      <td>6.094091</td>\n",
       "      <td>767</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>fixed maturity</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>7.826667</td>\n",
       "      <td>0.203636</td>\n",
       "      <td>4.269091</td>\n",
       "      <td>5280</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     word  good_score  bad_score  good_score_all  \\\n",
       "86   insurance subsidiary    0.925000   7.593846        0.168182   \n",
       "130   net interest income    0.798667   7.905000        0.544545   \n",
       "98          line business    0.931000   7.474444        0.423182   \n",
       "135           net revenue    0.900625   7.540000        0.655000   \n",
       "116            loss ratio    0.955000   7.850833        0.173636   \n",
       "127         mortgage loan    0.791000   8.332222        0.359545   \n",
       "76          future policy    0.925000   7.480000        0.168182   \n",
       "150        policy benefit    0.925000   7.610833        0.168182   \n",
       "85      insurance product    0.880000   7.723125        0.360000   \n",
       "91         invested asset    0.816000   8.008333        0.185455   \n",
       "92        investment gain    1.024444   7.718125        0.419091   \n",
       "93      investment income    0.986364   7.550556        0.493182   \n",
       "113             loss loss    0.946364   7.098235        0.473182   \n",
       "84       insurance policy    0.989091   7.157059        0.494545   \n",
       "59          expense ratio    0.925000   8.780000        0.168182   \n",
       "95          joint venture    0.923750   6.837000        0.671818   \n",
       "107      loan receivables    0.704286   5.870000        0.224091   \n",
       "73          following set    0.812000   7.024444        0.553636   \n",
       "123        million second    0.887500   7.448333        0.484091   \n",
       "71         fixed maturity    0.746667   7.826667        0.203636   \n",
       "\n",
       "     bad_score_all  count  good_nums  bad_nums  diff  \n",
       "86        4.487273   1246          4        13     9  \n",
       "130       2.155909   2101         15         6     9  \n",
       "98        6.115455   1069         10        18     8  \n",
       "135       2.741818    867         16         8     8  \n",
       "116       4.282273    846          4        12     8  \n",
       "127       6.817273   4022         10        18     8  \n",
       "76        4.080000   1214          4        12     8  \n",
       "150       4.151364   1121          4        12     8  \n",
       "85        5.616818   1022          9        16     7  \n",
       "91        4.368182    856          5        12     7  \n",
       "92        5.613182   2750          9        16     7  \n",
       "93        6.177727   3193         11        18     7  \n",
       "113       5.485000   2167         11        17     6  \n",
       "84        5.530455    861         11        17     6  \n",
       "59        3.990909    719          4        10     6  \n",
       "95        3.107727    743         16        10     6  \n",
       "107       0.266818   1129          7         1     6  \n",
       "73        2.873636    849         15         9     6  \n",
       "123       6.094091    767         12        18     6  \n",
       "71        4.269091   5280          6        12     6  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodvbad_path = os.path.join(\"data\", \"training_goodvbad\")\n",
    "if not os.path.isdir(goodvbad_path):\n",
    "    os.mkdir(goodvbad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.round(2).to_csv(\"data/training_goodvbad/{}_{}_{}_n{}-{}.csv\".format(sector[:8], score_type[:3], alpha, n_min, n_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainig data scores\n",
    "\n",
    "#Technology_envirnomental\n",
    "data_tech = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\training_goodvbad\\Technolo_env_0.5_n2-3.csv'\n",
    "\n",
    "#consumer cyclical_social\n",
    "data_consumer = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\training_goodvbad\\Consumer_soc_0.5_n2-3.csv'\n",
    "\n",
    "#financial services_governance\n",
    "data_financials = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\training_goodvbad\\Financia_gov_0.5_n2-3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tech=pd.read_csv(data_tech).iloc[:,1:]\n",
    "df_consumer=pd.read_csv(data_consumer).iloc[:,1:]\n",
    "df_financials=pd.read_csv(data_financials).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tech.isGood.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    91\n",
       " 0    79\n",
       "-1    30\n",
       "Name: isGood, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consumer.isGood.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load validation companies\n",
    "\n",
    "#consumer cyclical_social\n",
    "validation_cyclical_data = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\validation_data\\Consumer_soc_0.5.csv'\n",
    "\n",
    "#Technology_envirnomental\n",
    "validation_tech_data = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\validation_data\\Technolo_env_0.5.csv'\n",
    "\n",
    "#financial services_governance\n",
    "validation_financials_data = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\validation_data\\Financia_gov_0.5.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cyc=pd.read_csv(validation_cyclical_data, usecols=[1,2])\n",
    "validation_tech=pd.read_csv(validation_tech_data, usecols=[1,2])\n",
    "validation_financials=pd.read_csv(validation_financials_data, usecols=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))\n",
    "\n",
    "def get_cik(ticker):\n",
    "    \"\"\" Get the cik for the ticker specified by the input argument \n",
    "    Input:\n",
    "        ticker(str): ticker of the company e.g. \"FB\"\n",
    "    \"\"\"\n",
    "    return ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:]\n",
    "    \n",
    "def ngrams(s, n):\n",
    "    \"\"\" Get all the n-gram for input texts s\n",
    "    Input:\n",
    "        s (str): A string of texts with each word separated by a whitespace\n",
    "        n (int): n-gram to extract\n",
    "    Return:\n",
    "        [str]: A list of string in the following format ([['a', 'b'], ['b', 'c'], ['c', 'd']])\n",
    "    \"\"\"\n",
    "    \n",
    "    s = s.split(' ')\n",
    "    output = []\n",
    "    for i in range(len(s) - n + 1):\n",
    "        output.append(s[i:i+n])\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_count(doc, df_dict):\n",
    "    \"\"\" Count the number of good and bad words occurred in the document\n",
    "    Input:\n",
    "        doc (str): A string with all the words in the documents\n",
    "        df_dict (pd.DataFrame): A DataFrame with word and isGood column, generated by previous section\n",
    "        n_min, n_max (int): specify the ngram range used to generate the dictionary, should be consistent with how df_dict is generated\n",
    "    Return:\n",
    "        (dict): A dictionary with value good_count and bad_count\n",
    "    \"\"\"\n",
    "    grams = doc.split()\n",
    "    good_count = bad_count = 0\n",
    "    \n",
    "    for g in grams:\n",
    "        if g in df_dict[\"word\"].values:\n",
    "            val = df_dict[df_dict[\"word\"] == g][\"isGood\"].values\n",
    "            if val == 1:\n",
    "                good_count += 1\n",
    "            elif val == -1:\n",
    "                bad_count += 1\n",
    "\n",
    "    return {\"good_count\": good_count, \"bad_count\": bad_count}\n",
    "    \n",
    "def validation(df_topk, val_tickers, dict_threshold):\n",
    "    \"\"\" Perform the validation step\n",
    "    The validation rationale: Companies whose score are in upper 50% group are considered \"bad\" companies and the corresponding val_true = 1; 0 otherwise (in lower 50% group, which is considered a good company)\n",
    "    Input:\n",
    "        df_topk (pd.DataFrame): containes the sector specific dict\n",
    "        val_tickers (list): A list of tickers to be validated\n",
    "        dict_threshold (int): A gram is considered as a good word if its good_nums - bad_nums > threshold\n",
    "    \"\"\"\n",
    "    diff = df_topk[\"good_nums\"] - df_topk[\"bad_nums\"]\n",
    "    df_topk[\"isGood\"] = diff.apply(lambda x: 1 if x > dict_threshold else (\n",
    "        -1 if x < -dict_threshold else 0))\n",
    "\n",
    "    # 1 if good_nums - bad_nums > threshold; -1 if good_nums - bad_nums < -threshold; 0 otherwise\n",
    "    val_ciks = [get_cik(ticker) for ticker in val_tickers]\n",
    "    \n",
    "    ret_texts = get_texts(val_ciks, val_tickers) \n",
    "\n",
    "    val_pred = []\n",
    "    for doc in tqdm(ret_texts[\"docs\"]):\n",
    "        ret = get_count(doc, df_topk[[\"word\", \"isGood\"]], 2, 3)\n",
    "\n",
    "        if ret[\"good_count\"] - ret[\"bad_count\"] > 0:\n",
    "            val_pred.append(1)\n",
    "        else:\n",
    "            val_pred.append(0)\n",
    "    \n",
    "    print(\"val_pred: {}\".format(val_pred))\n",
    "    \n",
    "    return val_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:01, 14.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [04:37<00:00, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_pred: [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "precision: \n",
      "0.7\n",
      "recall: \n",
      "0.875\n",
      "accuracy: \n",
      "0.8\n",
      "Confusion Matrix: \n",
      "[[9 1]\n",
      " [3 7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# financials sector, governance\n",
    "val_tickers_financials = (pd.concat([validation_financials['good'], validation_financials['bad']])).tolist()\n",
    "\n",
    "# TODO: Update to the actual tickers to test\n",
    "# val_tickers = [\"FB\", \"GOOG\"] # should be a list of tickers you split into test set\n",
    "\n",
    "val_ciks = [get_cik(ticker) for ticker in val_tickers_financials]\n",
    "\n",
    "val_pred = validation(df_financials, val_tickers_financials, 2)   # df is the dictionary with good_num, bad_num, diff\n",
    "\n",
    "# val_true (list): A list of true labels for each companies (1 for good company, 0 for bad)\n",
    "val_true = np.concatenate([([i]*len(validation_financials['good'])) for i in [1,0]], axis=0).tolist()\n",
    "# val_true = [1, 1]\n",
    "\n",
    "cm = confusion_matrix(val_true, val_pred)\n",
    "prec = cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "rec = cm[1][1]/(cm[1][1]+cm[0][1])\n",
    "acc = (cm[1][1] + cm[0][0]) /(cm[1][0]+cm[0][1] + cm[1][1] + cm[0][0])\n",
    "\n",
    "print(\"precision: \\n{}\".format(prec))\n",
    "print(\"recall: \\n{}\".format(rec))\n",
    "print(\"accuracy: \\n{}\".format(acc))\n",
    "print(\"Confusion Matrix: \\n{}\".format(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_financials.isGood.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    106\n",
       "-1     63\n",
       " 1     31\n",
       "Name: isGood, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 is numb of good words\n",
    "# -1 is numb of bad words\n",
    "df_financials.isGood.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumer cyclical sector, social\n",
    "val_tickers_cyc = (pd.concat([validation_cyc['good'], validation_cyc['bad']])).tolist()\n",
    "\n",
    "# TODO: Update to the actual tickers to test\n",
    "# val_tickers = [\"FB\", \"GOOG\"] # should be a list of tickers you split into test set\n",
    "\n",
    "val_ciks = [get_cik(ticker) for ticker in val_tickers_cyc]\n",
    "\n",
    "val_pred = validation(df_consumer, val_tickers_cyc, 2)   # df is the dictionary with good_num, bad_num, diff\n",
    "\n",
    "# val_true (list): A list of true labels for each companies (1 for good company, 0 for bad)\n",
    "val_true = np.concatenate([([i]*len(validation_cyc['good'])) for i in [1,0]], axis=0).tolist()\n",
    "# val_true = [1, 1]\n",
    "cm = confusion_matrix(val_true, val_pred)\n",
    "prec = cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "rec = cm[1][1]/(cm[1][1]+cm[0][1])\n",
    "acc = (cm[1][1] + cm[0][0]) /(cm[1][0]+cm[0][1] + cm[1][1] + cm[0][0])\n",
    "\n",
    "print(\"precision: \\n{}\".format(prec))\n",
    "print(\"recall: \\n{}\".format(rec))\n",
    "print(\"accuracy: \\n{}\".format(acc))\n",
    "print(\"Confusion Matrix: \\n{}\".format(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 440.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# To remove all the previous files earlier than 2020\n",
    "for cik in tqdm(bad_cik):\n",
    "    tenk_path = os.path.join(\"data\", \"10k\", cik, \"rawtext\")\n",
    "    all_raws = os.listdir(tenk_path)\n",
    "    for filename in all_raws:\n",
    "        if filename[0] == '.':\n",
    "            continue\n",
    "        year = int(filename.split('_')[1].split('-')[0])\n",
    "        # print(year)\n",
    "        if year < 2020:\n",
    "            # print(os.path.join(tenk_path, filename))\n",
    "            os.remove(os.path.join(tenk_path, filename))\n",
    "    \n",
    "    tenq_path = os.path.join(\"data\", \"10q\", cik, \"rawtext\")\n",
    "    all_raws = os.listdir(tenq_path)\n",
    "    for filename in all_raws:\n",
    "        if filename[0] == '.':\n",
    "            continue\n",
    "        year = int(filename.split('_')[1].split('-')[0])\n",
    "        # print(year)\n",
    "        if year < 2020:\n",
    "            # print(os.path.join(tenk_path, filename))\n",
    "            os.remove(os.path.join(tenq_path, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File energy_good_vs_bad_uni_bi_tri.csv does not exist: 'energy_good_vs_bad_uni_bi_tri.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-234-c9dba302b136>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"energy_good_vs_bad_uni_bi_tri.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File energy_good_vs_bad_uni_bi_tri.csv does not exist: 'energy_good_vs_bad_uni_bi_tri.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"energy_good_vs_bad_uni_bi_tri.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation for approach 1 (tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ciks(tickers):\n",
    "    ciks = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        ciks.append(get_cik(ticker))\n",
    "\n",
    "    return ciks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dict_tfidf(good_ticker, bad_ticker, sector, score_type, rerun=False):\n",
    "    path = os.path.join(\"data\", \"tfidf_scores\", \"train\", \"{}_{}.csv\".format(sector, score_type))\n",
    "    if not rerun and os.path.exists(path):\n",
    "        df_tfidf = pd.read_csv(path, index_col=0)\n",
    "    else:\n",
    "        print(\"Train {} {}\".format(sector, score_type))\n",
    "        tickers = good_ticker + bad_ticker\n",
    "        ciks = get_ciks(tickers)\n",
    "\n",
    "        esgs = df_esg_score[df_esg_score[\"Company\"].isin(tickers)][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "\n",
    "        for t in not_listed:\n",
    "            if t in good_ticker or t in bad_ticker:\n",
    "                esgs = esgs.drop(esgs[esgs[\"Company\"] == t].index)\n",
    "\n",
    "        ret = get_texts(ciks, tickers)\n",
    "        docs = ret[\"docs\"]\n",
    "\n",
    "        cv = CountVectorizer(max_df=0.8, stop_words=stop_words, max_features=1000)\n",
    "        word_count_vector = cv.fit_transform(docs)\n",
    "\n",
    "        tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "        tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "        feature_names = cv.get_feature_names()\n",
    "\n",
    "        df_doc_word = pd.DataFrame(columns=feature_names, index=tickers)\n",
    "\n",
    "        for i, ticker in tqdm(enumerate(tickers)):\n",
    "            tf_idf_vector = tfidf_transformer.transform(cv.transform([docs[i]]))\n",
    "            \n",
    "            coo_matrix = tf_idf_vector.tocoo()\n",
    "            # coo_matrix: A sparse matrix in which coo_matrix.col stores word_idx, coo_matrix.data stores tfidf score\n",
    "            \n",
    "            tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "            for word_idx, tfidf in tuples:\n",
    "                df_doc_word.at[ticker, feature_names[word_idx]] = tfidf\n",
    "\n",
    "        df_doc_word = df_doc_word.iloc[:, df_doc_word.columns.isin(words.words())]\n",
    "        df_doc_word = df_doc_word.fillna(0)\n",
    "\n",
    "        feature_names = [name for name in feature_names if name in words.words()]\n",
    "\n",
    "        df_tfidf = pd.DataFrame(columns=[\"{}_beta\".format(score_type)], index=feature_names)\n",
    "\n",
    "        # for typ in [\"social\", \"governance\", \"environment\"]:\n",
    "        score = esgs[score_type]\n",
    "        slopes = []\n",
    "        \n",
    "        for word in feature_names:\n",
    "            tfidfs = df_doc_word[word].values.astype(float)\n",
    "            slope, intercept, *_ = linregress(tfidfs, score)\n",
    "            slopes.append(slope)\n",
    "        df_tfidf[\"{}_beta\".format(score_type)] = slopes\n",
    "\n",
    "        cols = df_tfidf.columns\n",
    "        alpha = 0.3\n",
    "\n",
    "        for col in cols: \n",
    "            betas = df_tfidf[col]\n",
    "            score_type = col.split('_')[0]\n",
    "            \n",
    "            upper_score = np.quantile(betas, 1 - alpha)\n",
    "            lower_score = np.quantile(betas, alpha)\n",
    "            \n",
    "            is_good = np.where(betas < lower_score, 1, 0) + np.where(betas > upper_score, -1, 0)\n",
    "            \n",
    "            df_tfidf[\"isGood\"] = is_good\n",
    "\n",
    "        df_tfidf.to_csv(path)\n",
    "    return df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_tfidf(df_tfidf, val_tickers):\n",
    "    \"\"\" Perform the validation step\n",
    "    The validation rationale: Companies whose score are in upper 50% group are considered \"bad\" companies and the corresponding val_true = 1; 0 otherwise (in lower 50% group, which is considered a good company)\n",
    "    Input:\n",
    "        df_topk (pd.DataFrame): containes the sector specific dict\n",
    "        val_tickers (list): A list of tickers to be validated\n",
    "    \"\"\"\n",
    "    df_tfidf[\"word\"] = df_tfidf.index\n",
    "    \n",
    "    # 1 if good_nums - bad_nums > threshold; -1 if good_nums - bad_nums < -threshold; 0 otherwise\n",
    "    val_ciks = [get_cik(ticker) for ticker in val_tickers]\n",
    "    \n",
    "    ret_texts = get_texts(val_ciks, val_tickers)\n",
    "\n",
    "    val_pred = []\n",
    "    for i, doc in tqdm(enumerate(ret_texts[\"docs\"])):\n",
    "        ret = get_count(doc, df_tfidf[[\"word\", \"isGood\"]])\n",
    "        print(val_tickers[i])\n",
    "        print(ret)\n",
    "\n",
    "        if ret[\"good_count\"] - ret[\"bad_count\"] > 0:\n",
    "            val_pred.append(1)\n",
    "        else:\n",
    "            val_pred.append(0)\n",
    "    \n",
    "    print(\"val_pred: {}\".format(val_pred))\n",
    "    \n",
    "    return val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    prec = cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "    rec = cm[1][1]/(cm[1][1]+cm[0][1])\n",
    "    acc = (cm[1][1] + cm[0][0]) /(cm[1][0]+cm[0][1] + cm[1][1] + cm[0][0])\n",
    "\n",
    "    print(\"precision: \\n{}\".format(prec))\n",
    "    print(\"recall: \\n{}\".format(rec))\n",
    "    print(\"accuracy: \\n{}\".format(acc))\n",
    "    print(\"Confusion Matrix: \\n{}\".format(cm))\n",
    "\n",
    "    return {\"cm\": cm, \"precision\": prec, \"recall\": rec, \"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_precision = pd.DataFrame(index=sectors, columns=score_types)\n",
    "df_val_recall = pd.DataFrame(index=sectors, columns=score_types)\n",
    "df_val_accuracy = pd.DataFrame(index=sectors, columns=score_types)\n",
    "cms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sectors = ['Consumer Cyclical', 'Energy', 'Industrials', 'Healthcare',\n",
    "#        'Basic Materials', 'Consumer Defensive', 'Utilities', 'Technology',\n",
    "#        'Financial Services', 'Communication Services', 'Real Estate']\n",
    "sectors = ['Technology', 'Financial Services']\n",
    "# sectors = [\"Energy\"]\n",
    "score_types = [\"governanceScore\", \"environmentScore\", \"socialScore\"]\n",
    "not_listed = [\"BBWI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = (('Technology', \"socialScore\"), ('Technology', \"governanceScore\"), ('Financial Services', \"governanceScore\"), ('Financial Services', \"socialScore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technology governanceScore\n",
      "Train Technology governanceScore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:01, 20.42it/s]\n",
      "26it [00:02, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2781869018412046\n",
      "-20.26052969246467\n",
      "              governanceScore_beta  isGood\n",
      "absence                  23.371701      -1\n",
      "absolute                  2.531386       0\n",
      "acceleration            -14.955977       0\n",
      "according                -8.046798       0\n",
      "accrue                   -9.275016       0\n",
      "accurate                -31.684920       1\n",
      "achievement              36.636676      -1\n",
      "acting                    3.153371       0\n",
      "actuarial               -10.684804       0\n",
      "adapt                    -2.811467       0\n",
      "adequacy                -12.426138       0\n",
      "adjacent                -13.577317       0\n",
      "adopt                    17.860144      -1\n",
      "advertising              19.208867      -1\n",
      "affiliate               -29.481376       1\n",
      "affirmative             -15.413332       0\n",
      "age                      -6.945850       0\n",
      "agent                     7.529615      -1\n",
      "agree                   -14.952437       0\n",
      "ai                       14.243032      -1\n",
      "aid                      -5.013420       0\n",
      "allegation               16.000036      -1\n",
      "alliance                -16.510590       0\n",
      "already                  57.271932      -1\n",
      "alternate               -70.764066       1\n",
      "always                  -63.973326       1\n",
      "amend                   -55.647265       1\n",
      "analyst                 -10.790642       0\n",
      "analytics                23.545816      -1\n",
      "analyze                  -6.845191       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 19.45it/s]\n",
      "1it [00:06,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NXPI\n",
      "{'good_count': 1118, 'bad_count': 878}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:08,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEL\n",
      "{'good_count': 1179, 'bad_count': 516}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:14,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADSK\n",
      "{'good_count': 1281, 'bad_count': 1929}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:19,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMAT\n",
      "{'good_count': 948, 'bad_count': 1207}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:27,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADBE\n",
      "{'good_count': 1690, 'bad_count': 2551}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:31,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STX\n",
      "{'good_count': 1270, 'bad_count': 1013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:33,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWKS\n",
      "{'good_count': 417, 'bad_count': 354}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:39,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVGO\n",
      "{'good_count': 1783, 'bad_count': 1571}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:43,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APH\n",
      "{'good_count': 975, 'bad_count': 810}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:48,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORCL\n",
      "{'good_count': 1088, 'bad_count': 1513}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:53,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BR\n",
      "{'good_count': 1154, 'bad_count': 1263}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:57,  4.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM\n",
      "{'good_count': 879, 'bad_count': 1153}\n",
      "val_pred: [1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]\n",
      "precision: \n",
      "0.5\n",
      "recall: \n",
      "0.5\n",
      "accuracy: \n",
      "0.5\n",
      "Confusion Matrix: \n",
      "[[3 3]\n",
      " [3 3]]\n",
      "Technology socialScore\n",
      "Train Technology socialScore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 27.86it/s]\n",
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "26it [00:01, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.049415165137436\n",
      "-51.32991409954689\n",
      "                socialScore_beta  isGood\n",
      "absolute              -41.552547       0\n",
      "acceleration         -145.860321       1\n",
      "according             -91.032811       1\n",
      "accrue                132.974233      -1\n",
      "accuracy             -132.755780       1\n",
      "accused                20.496990       0\n",
      "acting                -97.882921       1\n",
      "actuarial              42.163320      -1\n",
      "adapt                  79.988372      -1\n",
      "add                   -79.984993       1\n",
      "added                  74.655971      -1\n",
      "adequacy                2.932204       0\n",
      "adjacent               26.250535      -1\n",
      "administration         76.977098      -1\n",
      "advantageous           25.202743      -1\n",
      "advertising          -191.448667       1\n",
      "advice                -46.012701       0\n",
      "advisory              -91.680949       1\n",
      "affiliate             -48.896739       0\n",
      "affirmative           -20.929766       0\n",
      "age                   -80.059570       1\n",
      "agree                -142.632976       1\n",
      "ai                     86.013757      -1\n",
      "air                   -62.506893       1\n",
      "align                 133.475671      -1\n",
      "allegation             15.723383       0\n",
      "allegedly              49.384890      -1\n",
      "already              -197.250057       1\n",
      "alternate              -7.304998       0\n",
      "always                150.279120      -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 37.38it/s]\n",
      "1it [00:05,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APH\n",
      "{'good_count': 1208, 'bad_count': 1313}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:09,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLW\n",
      "{'good_count': 845, 'bad_count': 1198}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:12,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRMB\n",
      "{'good_count': 759, 'bad_count': 600}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:16,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMAT\n",
      "{'good_count': 903, 'bad_count': 1369}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:19,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPGP\n",
      "{'good_count': 722, 'bad_count': 1076}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:22,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACN\n",
      "{'good_count': 757, 'bad_count': 782}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:27,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTV\n",
      "{'good_count': 1200, 'bad_count': 1657}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:30,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRSN\n",
      "{'good_count': 1040, 'bad_count': 553}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:37,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTNT\n",
      "{'good_count': 1904, 'bad_count': 2147}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:43,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTSH\n",
      "{'good_count': 1206, 'bad_count': 1454}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:45,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JKHY\n",
      "{'good_count': 690, 'bad_count': 368}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:51,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADSK\n",
      "{'good_count': 1494, 'bad_count': 1404}\n",
      "val_pred: [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "precision: \n",
      "0.16666666666666666\n",
      "recall: \n",
      "0.25\n",
      "accuracy: \n",
      "0.3333333333333333\n",
      "Confusion Matrix: \n",
      "[[3 3]\n",
      " [5 1]]\n",
      "Financial Services governanceScore\n",
      "Train Financial Services governanceScore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:02,  9.85it/s]\n",
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "26it [00:07,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.86002617141975\n",
      "-29.921342888334433\n",
      "               governanceScore_beta  isGood\n",
      "absence                  218.691697      -1\n",
      "absorb                   330.557518      -1\n",
      "acceptance               119.216701      -1\n",
      "accident                 -16.774071       0\n",
      "accommodate             -115.317182       1\n",
      "accretion                148.330018      -1\n",
      "accrue                   118.694648      -1\n",
      "accuracy                 102.557955      -1\n",
      "administrator           -198.813240       1\n",
      "advice                   -14.870197       0\n",
      "adviser                   33.337129       0\n",
      "affair                   -71.944632       1\n",
      "affordable              -106.894280       1\n",
      "agricultural              16.124457       0\n",
      "al                       213.461274      -1\n",
      "allege                    76.574851       0\n",
      "allocate                 -92.421991       1\n",
      "analyst                  130.400798      -1\n",
      "analytical                48.532053       0\n",
      "analytics                 11.766669       0\n",
      "analyze                  -21.997224       0\n",
      "annuity                   -0.594749       0\n",
      "antitrust                145.507030      -1\n",
      "appeal                    68.200796       0\n",
      "appetite                  21.964003       0\n",
      "appraisal               -108.107444       1\n",
      "appreciation              61.656815       0\n",
      "appropriately           -348.220156       1\n",
      "ar                       -71.506414       1\n",
      "argentine                 22.526682       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  9.27it/s]\n",
      "1it [00:07,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HBAN\n",
      "{'good_count': 1818, 'bad_count': 1150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:13,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AXP\n",
      "{'good_count': 969, 'bad_count': 2016}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:19,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYF\n",
      "{'good_count': 1390, 'bad_count': 1147}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:24,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYPL\n",
      "{'good_count': 766, 'bad_count': 1334}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:31,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICE\n",
      "{'good_count': 1262, 'bad_count': 1310}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:35,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSCI\n",
      "{'good_count': 936, 'bad_count': 1413}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:15, 16.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIVB\n",
      "{'good_count': 12893, 'bad_count': 5134}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [02:20, 32.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIG\n",
      "{'good_count': 16108, 'bad_count': 7637}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [02:42, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMA\n",
      "{'good_count': 5944, 'bad_count': 2828}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:56, 24.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRB\n",
      "{'good_count': 5189, 'bad_count': 1631}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:10, 21.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CINF\n",
      "{'good_count': 4373, 'bad_count': 1734}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [03:39, 18.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNM\n",
      "{'good_count': 5953, 'bad_count': 3060}\n",
      "val_pred: [1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: \n",
      "0.3333333333333333\n",
      "recall: \n",
      "0.25\n",
      "accuracy: \n",
      "0.16666666666666666\n",
      "Confusion Matrix: \n",
      "[[0 6]\n",
      " [4 2]]\n",
      "Financial Services socialScore\n",
      "Train Financial Services socialScore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:04,  5.34it/s]\n",
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "25it [00:05,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.768942496850784\n",
      "-88.3605190618177\n",
      "              socialScore_beta  isGood\n",
      "absolute           -246.051967       1\n",
      "absorb             -494.820310       1\n",
      "acceptance         -921.502007       1\n",
      "accident             18.179422       0\n",
      "according           -89.815404       1\n",
      "accretion           -29.480024       0\n",
      "accrue             -164.359646       1\n",
      "accumulation          1.286975       0\n",
      "actuarial            55.592047      -1\n",
      "additionally         36.055385       0\n",
      "advertising         -86.481885       0\n",
      "advice              -37.735113       0\n",
      "adviser              10.348316       0\n",
      "advisor              -5.721846       0\n",
      "advisory            -25.414694       0\n",
      "affordable         -218.525827       1\n",
      "aging               -25.802330       0\n",
      "aircraft             75.559218      -1\n",
      "allegation          156.609218      -1\n",
      "allege               52.796757      -1\n",
      "allocate           -207.517875       1\n",
      "analyst            -337.463970       1\n",
      "analytical           90.299183      -1\n",
      "annuity               1.524071       0\n",
      "antitrust            47.569547       0\n",
      "appeal              -38.546135       0\n",
      "appear              259.375113      -1\n",
      "appetite           -376.791189       1\n",
      "appraisal           -64.409121       0\n",
      "appreciation       -190.484499       1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.17it/s]\n",
      "1it [00:10, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFG\n",
      "{'good_count': 2018, 'bad_count': 2051}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:16,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOE\n",
      "{'good_count': 1176, 'bad_count': 1446}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:23,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRV\n",
      "{'good_count': 798, 'bad_count': 3433}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:28,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE\n",
      "{'good_count': 895, 'bad_count': 1624}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:35,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICE\n",
      "{'good_count': 1225, 'bad_count': 3486}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:37,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WU\n",
      "{'good_count': 611, 'bad_count': 695}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [01:04, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USB\n",
      "{'good_count': 5075, 'bad_count': 2814}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:38, 19.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTB\n",
      "{'good_count': 7228, 'bad_count': 3584}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [02:00, 20.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMA\n",
      "{'good_count': 4031, 'bad_count': 4562}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:15, 18.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS\n",
      "{'good_count': 3522, 'bad_count': 2369}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [02:23, 15.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS\n",
      "{'good_count': 1708, 'bad_count': 1219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [02:34, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STT\n",
      "{'good_count': 2785, 'bad_count': 1581}\n",
      "val_pred: [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1]\n",
      "precision: \n",
      "0.0\n",
      "recall: \n",
      "0.0\n",
      "accuracy: \n",
      "0.08333333333333333\n",
      "Confusion Matrix: \n",
      "[[1 5]\n",
      " [6 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for sector in sectors:\n",
    "    for score_type in score_types:\n",
    "        if (sector, score_type) not in pair:\n",
    "            continue\n",
    "        print(\"{} {}\".format(sector, score_type))\n",
    "        esgs = df_esg_score[df_esg_score[\"sector\"] == sector][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "        score = esgs[score_type]\n",
    "        alpha = 0.3\n",
    "        upper_score = np.quantile(score, 1 - alpha)\n",
    "        lower_score = np.quantile(score, alpha)\n",
    "\n",
    "        good_companies = list(esgs[esgs[score_type] < lower_score][\"Company\"].values)\n",
    "        bad_companies = list(esgs[esgs[score_type] > upper_score][\"Company\"].values)\n",
    "                \n",
    "        #training set\n",
    "        train_good = random.sample(list(good_companies), int(len(good_companies)*0.7))\n",
    "        train_bad = random.sample(list(bad_companies), int(len(bad_companies)*0.7))\n",
    "\n",
    "        df_tfidf = train_dict_tfidf(train_good, train_bad, sector, score_type, rerun=False)\n",
    "        \n",
    "        #validation set\n",
    "        validate_good = [ticker for ticker in good_companies if ticker not in train_good]\n",
    "        validate_bad = [ticker for ticker in bad_companies if ticker not in train_bad]\n",
    "\n",
    "        val_tickers = validate_good + validate_bad\n",
    "        \n",
    "        val_pred = validation_tfidf(df_tfidf, val_tickers)   # df is the dictionary with good_num, bad_num, diff\n",
    "        val_true = [1] * len(validate_good) + [0] * len(validate_bad)\n",
    "\n",
    "        val_performance = get_report(val_true, val_pred)\n",
    "        df_val_precision.at[sector, score_type] = val_performance[\"precision\"]\n",
    "        df_val_recall.at[sector, score_type] = val_performance[\"recall\"]\n",
    "        df_val_accuracy.at[sector, score_type] = val_performance[\"accuracy\"]\n",
    "        cms.append(val_performance[\"cm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>governanceScore</th>\n",
       "      <th>environmentScore</th>\n",
       "      <th>socialScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrials</th>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Services</th>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   governanceScore environmentScore socialScore\n",
       "Consumer Cyclical              0.5             0.25    0.444444\n",
       "Industrials                    0.4              NaN         NaN\n",
       "Utilities                      0.0              0.5         NaN\n",
       "Technology                     0.5              NaN        0.25\n",
       "Financial Services            0.25              NaN         0.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>governanceScore</th>\n",
       "      <th>environmentScore</th>\n",
       "      <th>socialScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrials</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Services</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   governanceScore environmentScore socialScore\n",
       "Consumer Cyclical              0.5         0.333333    0.416667\n",
       "Industrials               0.416667              NaN         NaN\n",
       "Utilities                      0.0              0.5         NaN\n",
       "Technology                     0.5              NaN    0.333333\n",
       "Financial Services        0.166667              NaN    0.083333"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>governanceScore</th>\n",
       "      <th>environmentScore</th>\n",
       "      <th>socialScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrials</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Services</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   governanceScore environmentScore socialScore\n",
       "Consumer Cyclical         0.333333         0.166667    0.666667\n",
       "Industrials               0.333333              NaN         NaN\n",
       "Utilities                      0.0         0.666667         NaN\n",
       "Technology                     0.5              NaN    0.166667\n",
       "Financial Services        0.333333              NaN         0.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4, 2],\n",
       "        [4, 2]]),\n",
       " array([[3, 3],\n",
       "        [5, 1]]),\n",
       " array([[1, 5],\n",
       "        [2, 4]]),\n",
       " array([[1, 5],\n",
       "        [3, 3]]),\n",
       " array([[3, 3],\n",
       "        [4, 2]]),\n",
       " array([[0, 3],\n",
       "        [3, 0]]),\n",
       " array([[1, 2],\n",
       "        [1, 2]]),\n",
       " array([[3, 3],\n",
       "        [3, 3]]),\n",
       " array([[3, 3],\n",
       "        [5, 1]]),\n",
       " array([[0, 6],\n",
       "        [4, 2]]),\n",
       " array([[1, 5],\n",
       "        [6, 0]])]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>governanceScore</th>\n",
       "      <th>environmentScore</th>\n",
       "      <th>socialScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Energy</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       governanceScore environmentScore socialScore\n",
       "Energy             0.5              0.5         0.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Consumer Cyclical socialScore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 27.44it/s]\n",
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "24it [00:02,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.06955651714321\n",
      "-53.54111784783206\n",
      "             socialScore_beta  isGood\n",
      "accept              34.720252       0\n",
      "accessory          -39.541716       0\n",
      "accord            -172.654997       1\n",
      "achievement        127.554267      -1\n",
      "actuarial          439.797658      -1\n",
      "add                218.156139      -1\n",
      "adjust             280.132074      -1\n",
      "adopt               83.043171      -1\n",
      "advance            -29.159821       0\n",
      "advanced            37.672048       0\n",
      "advertising         77.588309       0\n",
      "affiliate           -1.181519       0\n",
      "age                 14.487396       0\n",
      "air                 23.887095       0\n",
      "aluminum            13.189829       0\n",
      "amend             -689.686912       1\n",
      "amort              -98.618887       1\n",
      "analyst             16.867392       0\n",
      "apparel              9.501550       0\n",
      "appear             189.283871      -1\n",
      "approval           489.704555      -1\n",
      "arise              356.007643      -1\n",
      "asp                  4.514310       0\n",
      "assert             504.370988      -1\n",
      "assess            -154.142831       1\n",
      "assigned            -0.481985       0\n",
      "associate           11.596587       0\n",
      "attack             465.401898      -1\n",
      "attorney          -174.666265       1\n",
      "auction           -456.359743       1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 37.69it/s]\n",
      "1it [00:03,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBHS\n",
      "{'good_count': 209, 'bad_count': 817}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:06,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHK\n",
      "{'good_count': 512, 'bad_count': 1309}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:13,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL\n",
      "{'good_count': 1113, 'bad_count': 1737}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:16,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPC\n",
      "{'good_count': 367, 'bad_count': 916}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:18,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOW\n",
      "{'good_count': 341, 'bad_count': 679}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:24,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAS\n",
      "{'good_count': 2015, 'bad_count': 1818}\n",
      "F\n",
      "{'good_count': 0, 'bad_count': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:32,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA\n",
      "{'good_count': 1429, 'bad_count': 2502}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:36,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPZ\n",
      "{'good_count': 370, 'bad_count': 888}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:42,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPE\n",
      "{'good_count': 2924, 'bad_count': 2172}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:46,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAR\n",
      "{'good_count': 2637, 'bad_count': 1791}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:48,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROL\n",
      "{'good_count': 255, 'bad_count': 766}\n",
      "val_pred: [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sector = 'Consumer Cyclical'\n",
    "score_types = \"environmentScore\"\n",
    "\n",
    "esgs = df_esg_score[df_esg_score[\"sector\"] == sector][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "score = esgs[score_type]\n",
    "alpha = 0.3\n",
    "upper_score = np.quantile(score, 1 - alpha)\n",
    "lower_score = np.quantile(score, alpha)\n",
    "\n",
    "bad_companies = list(esgs[esgs[score_type] > upper_score][\"Company\"].values)\n",
    "good_companies = list(esgs[esgs[score_type] < lower_score][\"Company\"].values)\n",
    "\n",
    "for t in not_listed:\n",
    "    if t in bad_companies:\n",
    "        bad_companies.remove(t)\n",
    "    if t in good_companies:\n",
    "        good_companies.remove(t)\n",
    "        \n",
    "#training set\n",
    "train_good = random.sample(list(good_companies), int(len(good_companies)*0.7))\n",
    "train_bad = random.sample(list(bad_companies), int(len(bad_companies)*0.7))\n",
    "\n",
    "df_tfidf = train_dict_tfidf(train_good, train_bad, sector, score_type, rerun=False)\n",
    "\n",
    "#validation set\n",
    "validate_good = [ticker for ticker in good_companies if ticker not in train_good]\n",
    "validate_bad = [ticker for ticker in bad_companies if ticker not in train_bad]\n",
    "\n",
    "val_tickers = validate_good + validate_bad\n",
    "\n",
    "val_pred = validation_tfidf(df_tfidf, val_tickers)   # df is the dictionary with good_num, bad_num, diff\n",
    "val_true = [1] * len(validate_good) + [0] * len(validate_bad)\n",
    "\n",
    "# val_performance = get_report(val_true, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: \n",
      "0.16666666666666666\n",
      "recall: \n",
      "0.3333333333333333\n",
      "accuracy: \n",
      "0.4166666666666667\n",
      "Confusion Matrix: \n",
      "[[4 2]\n",
      " [5 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cm': array([[4, 2],\n",
       "        [5, 1]]),\n",
       " 'precision': 0.16666666666666666,\n",
       " 'recall': 0.3333333333333333,\n",
       " 'accuracy': 0.4166666666666667}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_report(val_true, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumer cyclical sector, social\n",
    "val_tickers_cyc = (pd.concat([validation_cyc['good'], validation_cyc['bad']])).tolist()\n",
    "\n",
    "# TODO: Update to the actual tickers to test\n",
    "# val_tickers = [\"FB\", \"GOOG\"] # should be a list of tickers you split into test set\n",
    "\n",
    "val_ciks = [get_cik(ticker) for ticker in val_tickers_cyc]\n",
    "\n",
    "val_pred = validation(df_consumer, val_tickers_cyc, 2)   # df is the dictionary with good_num, bad_num, diff\n",
    "\n",
    "# val_true (list): A list of true labels for each companies (1 for good company, 0 for bad)\n",
    "val_true = np.concatenate([([i]*len(validation_cyc['good'])) for i in [1,0]], axis=0).tolist()\n",
    "# val_true = [1, 1]\n",
    "cm = confusion_matrix(val_true, val_pred)\n",
    "prec = cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "rec = cm[1][1]/(cm[1][1]+cm[0][1])\n",
    "acc = (cm[1][1] + cm[0][0]) /(cm[1][0]+cm[0][1] + cm[1][1] + cm[0][0])\n",
    "\n",
    "print(\"precision: \\n{}\".format(prec))\n",
    "print(\"recall: \\n{}\".format(rec))\n",
    "print(\"accuracy: \\n{}\".format(acc))\n",
    "print(\"Confusion Matrix: \\n{}\".format(cm))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcf325ffca4e7352bcfac699b7999bb028ddd94d8390136137b75043a4ee01b0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
