{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/luckywang/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import linregress\n",
    "from utils.preprocessing import get_texts\n",
    "from utils.preprocessing import get_texts, stop_words\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esg_score = pd.read_excel(\"data/esg_score.xlsx\", sheet_name = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_tickers = ticker_library[\"ticker\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esg_score = df_esg_score[df_esg_score[\"Company\"].isin(legit_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_esg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Modify here for different sectors and score_types\n",
    "# set the sector and ESG type for the analysis\n",
    "sector = \"Financial Services\"\n",
    "# sector = \"Energy\"\n",
    "\n",
    "score_type = \"governanceScore\"\n",
    "# score_type = \"environmentScore\"\n",
    "# score_type = \"socialScore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set\n",
    "train_bad=random.sample(list(bad_companies), int(len(bad_companies)*0.7))\n",
    "train_good=random.sample(list(good_companies), int(len(good_companies)*0.7))\n",
    "\n",
    "#validation set\n",
    "validate_bad = [i for i in bad_companies if i not in train_bad]\n",
    "validate_good = [i for i in good_companies if i not in train_good]\n",
    "\n",
    "# validate_good = pd.DataFrame(validate_good) \n",
    "# validate_bad = pd.DataFrame(validate_bad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.DataFrame({'good':validate_good, 'bad':validate_bad})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the list of good and bad companies\n",
    "validation_path = os.path.join(\"data\", \"validation_data\")\n",
    "if not os.path.isdir(validation_path):\n",
    "    os.mkdir(validation_path)\n",
    "\n",
    "validation.to_csv(\"data/validation_data/{}_{}_{}.csv\".format(sector[:8], score_type[:3], alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(train_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(validate_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esgs[esgs[score_type] > upper_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data bad companies scores\n",
    "train_bad_scores=pd.DataFrame()\n",
    "for i in train_bad:\n",
    "    df_bad=esgs[esgs['Company'] == i]\n",
    "    train_bad_scores=train_bad_scores.append(df_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data good companies scores\n",
    "train_good_scores=pd.DataFrame()\n",
    "\n",
    "for i in train_good:\n",
    "    df_good=esgs[esgs['Company'] == i]\n",
    "    train_good_scores =train_good_scores.append(df_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_companies_score = esgs[esgs[score_type] > upper_score][score_type].values\n",
    "# good_companies_score = esgs[esgs[score_type] < lower_score][score_type].values\n",
    "\n",
    "good_companies_score_training=train_good_scores[score_type]\n",
    "bad_companies_score_training=train_bad_scores[score_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.138499999999999 6.109999999999999\n"
     ]
    }
   ],
   "source": [
    "avg_bad = np.mean(bad_companies_score_training)\n",
    "avg_good = np.mean(good_companies_score_training)\n",
    "print(avg_bad, avg_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.23 10.23\n"
     ]
    }
   ],
   "source": [
    "print(upper_score, lower_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohammed Al Harmoudi\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))\n",
    "good_cik = []\n",
    "bad_cik = []\n",
    "for ticker in train_good:    \n",
    "    try:\n",
    "        # for a given ticker, find its cik number through th ticker library\n",
    "        good_cik.append(ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:])\n",
    "    except:\n",
    "        # if could not find cik, give it a empty cik\n",
    "        good_cik.append('')\n",
    "\n",
    "for ticker in train_bad:    \n",
    "    try:\n",
    "        # for a given ticker, find its cik number through th ticker library\n",
    "        bad_cik.append(ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:])\n",
    "    except:\n",
    "        # if could not find cik, give it a empty cik\n",
    "        bad_cik.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret_good = get_texts(good_cik, train_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret_bad = get_texts(bad_cik, train_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_docs = ret_good[\"docs\"]\n",
    "bad_docs = ret_bad[\"docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohammed Al Harmoudi\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# TODO: Modify here for different ngram range\n",
    "n_min = 2\n",
    "n_max = 3\n",
    "cv = CountVectorizer(max_df=0.7, stop_words=stop_words, max_features=200, ngram_range=(n_min, n_max))\n",
    "word_count_vector = cv.fit_transform(good_docs + bad_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_feature = word_count_vector.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"word\": [], \"good_score\": [], \"bad_score\": [], \"good_score_all\": []\n",
    "    , \"bad_score_all\": [], \"count\": [], \"good_nums\": [], \"bad_nums\": []}\n",
    "\n",
    "for feature_idx, word in enumerate(feature_names):\n",
    "    good_sum = bad_sum = good_num = bad_num = 0\n",
    "\n",
    "    for i, doc_set in enumerate(good_docs):\n",
    "        if word in doc_set:\n",
    "            good_num += 1\n",
    "            good_sum += good_companies_score[i]\n",
    "    for i, doc_set in enumerate(bad_docs):\n",
    "        if word in doc_set:\n",
    "            bad_num += 1\n",
    "            bad_sum += bad_companies_score[i]\n",
    "    \n",
    "    # print(\"word: {}\".format(word))\n",
    "    d[\"word\"].append(word) \n",
    "    \n",
    "    if good_num:\n",
    "        d[\"good_score\"].append(good_sum / good_num)\n",
    "    else:\n",
    "        d[\"good_score\"].append(0)\n",
    "    if bad_num:\n",
    "        d[\"bad_score\"].append(bad_sum / bad_num)\n",
    "    else:\n",
    "        d[\"bad_score\"].append(0)\n",
    "\n",
    "    d[\"good_score_all\"].append(good_sum / len(good_docs))\n",
    "    d[\"bad_score_all\"].append(bad_sum / len(bad_docs))\n",
    "\n",
    "    d[\"count\"].append(count_feature[feature_idx])\n",
    "    d[\"good_nums\"].append(good_num)\n",
    "    d[\"bad_nums\"].append(bad_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accident year</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>7.668571</td>\n",
       "      <td>0.066364</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>2329</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accompanying note</td>\n",
       "      <td>1.002308</td>\n",
       "      <td>7.452308</td>\n",
       "      <td>0.592273</td>\n",
       "      <td>4.403636</td>\n",
       "      <td>847</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acquisition cost</td>\n",
       "      <td>0.867273</td>\n",
       "      <td>7.795625</td>\n",
       "      <td>0.433636</td>\n",
       "      <td>5.669545</td>\n",
       "      <td>1249</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adjusted earnings</td>\n",
       "      <td>1.016667</td>\n",
       "      <td>6.565000</td>\n",
       "      <td>0.138636</td>\n",
       "      <td>0.596818</td>\n",
       "      <td>918</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adjusted operating</td>\n",
       "      <td>1.042857</td>\n",
       "      <td>5.356000</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>1.217273</td>\n",
       "      <td>1454</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adjustment expense</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>7.531111</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>3.080909</td>\n",
       "      <td>1133</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aflac japan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266818</td>\n",
       "      <td>732</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allowance loan</td>\n",
       "      <td>0.835833</td>\n",
       "      <td>8.014615</td>\n",
       "      <td>0.455909</td>\n",
       "      <td>4.735909</td>\n",
       "      <td>951</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amount except</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>9.350000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>779</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>available sale</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>7.723077</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>4.563636</td>\n",
       "      <td>871</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>average total</td>\n",
       "      <td>0.822727</td>\n",
       "      <td>7.626000</td>\n",
       "      <td>0.411364</td>\n",
       "      <td>3.466364</td>\n",
       "      <td>885</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bank holding</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8.168889</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>3.341818</td>\n",
       "      <td>991</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bank holding company</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8.168889</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>3.341818</td>\n",
       "      <td>721</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>basel iii</td>\n",
       "      <td>0.779000</td>\n",
       "      <td>8.810000</td>\n",
       "      <td>0.354091</td>\n",
       "      <td>3.203636</td>\n",
       "      <td>1114</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>business segment</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>7.655000</td>\n",
       "      <td>0.658636</td>\n",
       "      <td>5.567273</td>\n",
       "      <td>1263</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>capital gain</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>7.287000</td>\n",
       "      <td>0.192273</td>\n",
       "      <td>3.312273</td>\n",
       "      <td>997</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>capital ratio</td>\n",
       "      <td>0.839167</td>\n",
       "      <td>7.992500</td>\n",
       "      <td>0.457727</td>\n",
       "      <td>5.812727</td>\n",
       "      <td>1804</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>card loan</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>8.464000</td>\n",
       "      <td>0.207273</td>\n",
       "      <td>1.923636</td>\n",
       "      <td>751</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>card member</td>\n",
       "      <td>1.003333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1435</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cash collateral</td>\n",
       "      <td>0.915625</td>\n",
       "      <td>8.488571</td>\n",
       "      <td>0.665909</td>\n",
       "      <td>5.401818</td>\n",
       "      <td>957</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word  good_score  bad_score  good_score_all  \\\n",
       "0          accident year    0.730000   7.668571        0.066364   \n",
       "1      accompanying note    1.002308   7.452308        0.592273   \n",
       "2       acquisition cost    0.867273   7.795625        0.433636   \n",
       "3      adjusted earnings    1.016667   6.565000        0.138636   \n",
       "4     adjusted operating    1.042857   5.356000        0.331818   \n",
       "5     adjustment expense    0.925000   7.531111        0.168182   \n",
       "6            aflac japan    0.000000   5.870000        0.000000   \n",
       "7         allowance loan    0.835833   8.014615        0.455909   \n",
       "8          amount except    0.616000   9.350000        0.140000   \n",
       "9         available sale    0.760000   7.723077        0.345455   \n",
       "10         average total    0.822727   7.626000        0.411364   \n",
       "11          bank holding    0.800000   8.168889        0.436364   \n",
       "12  bank holding company    0.800000   8.168889        0.436364   \n",
       "13             basel iii    0.779000   8.810000        0.354091   \n",
       "14      business segment    0.966000   7.655000        0.658636   \n",
       "15          capital gain    0.846000   7.287000        0.192273   \n",
       "16         capital ratio    0.839167   7.992500        0.457727   \n",
       "17             card loan    0.912000   8.464000        0.207273   \n",
       "18           card member    1.003333   0.000000        0.136818   \n",
       "19       cash collateral    0.915625   8.488571        0.665909   \n",
       "\n",
       "    bad_score_all  count  good_nums  bad_nums  \n",
       "0        2.440000   2329          2         7  \n",
       "1        4.403636    847         13        13  \n",
       "2        5.669545   1249         11        16  \n",
       "3        0.596818    918          3         2  \n",
       "4        1.217273   1454          7         5  \n",
       "5        3.080909   1133          4         9  \n",
       "6        0.266818    732          0         1  \n",
       "7        4.735909    951         12        13  \n",
       "8        2.125000    779          5         5  \n",
       "9        4.563636    871         10        13  \n",
       "10       3.466364    885         11        10  \n",
       "11       3.341818    991         12         9  \n",
       "12       3.341818    721         12         9  \n",
       "13       3.203636   1114         10         8  \n",
       "14       5.567273   1263         15        16  \n",
       "15       3.312273    997          5        10  \n",
       "16       5.812727   1804         12        16  \n",
       "17       1.923636    751          5         5  \n",
       "18       0.000000   1435          3         0  \n",
       "19       5.401818    957         16        14  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"diff\"] = abs(df[\"good_nums\"] - df[\"bad_nums\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"diff\", ascending=False)#.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>good_score</th>\n",
       "      <th>bad_score</th>\n",
       "      <th>good_score_all</th>\n",
       "      <th>bad_score_all</th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>insurance subsidiary</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>7.593846</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>4.487273</td>\n",
       "      <td>1246</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>net interest income</td>\n",
       "      <td>0.798667</td>\n",
       "      <td>7.905000</td>\n",
       "      <td>0.544545</td>\n",
       "      <td>2.155909</td>\n",
       "      <td>2101</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>line business</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>7.474444</td>\n",
       "      <td>0.423182</td>\n",
       "      <td>6.115455</td>\n",
       "      <td>1069</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>net revenue</td>\n",
       "      <td>0.900625</td>\n",
       "      <td>7.540000</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>2.741818</td>\n",
       "      <td>867</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>loss ratio</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>7.850833</td>\n",
       "      <td>0.173636</td>\n",
       "      <td>4.282273</td>\n",
       "      <td>846</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>mortgage loan</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>8.332222</td>\n",
       "      <td>0.359545</td>\n",
       "      <td>6.817273</td>\n",
       "      <td>4022</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>future policy</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>7.480000</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>1214</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>policy benefit</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>7.610833</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>4.151364</td>\n",
       "      <td>1121</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>insurance product</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>7.723125</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>5.616818</td>\n",
       "      <td>1022</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>invested asset</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>8.008333</td>\n",
       "      <td>0.185455</td>\n",
       "      <td>4.368182</td>\n",
       "      <td>856</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>investment gain</td>\n",
       "      <td>1.024444</td>\n",
       "      <td>7.718125</td>\n",
       "      <td>0.419091</td>\n",
       "      <td>5.613182</td>\n",
       "      <td>2750</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>investment income</td>\n",
       "      <td>0.986364</td>\n",
       "      <td>7.550556</td>\n",
       "      <td>0.493182</td>\n",
       "      <td>6.177727</td>\n",
       "      <td>3193</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>loss loss</td>\n",
       "      <td>0.946364</td>\n",
       "      <td>7.098235</td>\n",
       "      <td>0.473182</td>\n",
       "      <td>5.485000</td>\n",
       "      <td>2167</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>insurance policy</td>\n",
       "      <td>0.989091</td>\n",
       "      <td>7.157059</td>\n",
       "      <td>0.494545</td>\n",
       "      <td>5.530455</td>\n",
       "      <td>861</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>expense ratio</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>3.990909</td>\n",
       "      <td>719</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>joint venture</td>\n",
       "      <td>0.923750</td>\n",
       "      <td>6.837000</td>\n",
       "      <td>0.671818</td>\n",
       "      <td>3.107727</td>\n",
       "      <td>743</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>loan receivables</td>\n",
       "      <td>0.704286</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>0.224091</td>\n",
       "      <td>0.266818</td>\n",
       "      <td>1129</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>following set</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>7.024444</td>\n",
       "      <td>0.553636</td>\n",
       "      <td>2.873636</td>\n",
       "      <td>849</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>million second</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>7.448333</td>\n",
       "      <td>0.484091</td>\n",
       "      <td>6.094091</td>\n",
       "      <td>767</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>fixed maturity</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>7.826667</td>\n",
       "      <td>0.203636</td>\n",
       "      <td>4.269091</td>\n",
       "      <td>5280</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     word  good_score  bad_score  good_score_all  \\\n",
       "86   insurance subsidiary    0.925000   7.593846        0.168182   \n",
       "130   net interest income    0.798667   7.905000        0.544545   \n",
       "98          line business    0.931000   7.474444        0.423182   \n",
       "135           net revenue    0.900625   7.540000        0.655000   \n",
       "116            loss ratio    0.955000   7.850833        0.173636   \n",
       "127         mortgage loan    0.791000   8.332222        0.359545   \n",
       "76          future policy    0.925000   7.480000        0.168182   \n",
       "150        policy benefit    0.925000   7.610833        0.168182   \n",
       "85      insurance product    0.880000   7.723125        0.360000   \n",
       "91         invested asset    0.816000   8.008333        0.185455   \n",
       "92        investment gain    1.024444   7.718125        0.419091   \n",
       "93      investment income    0.986364   7.550556        0.493182   \n",
       "113             loss loss    0.946364   7.098235        0.473182   \n",
       "84       insurance policy    0.989091   7.157059        0.494545   \n",
       "59          expense ratio    0.925000   8.780000        0.168182   \n",
       "95          joint venture    0.923750   6.837000        0.671818   \n",
       "107      loan receivables    0.704286   5.870000        0.224091   \n",
       "73          following set    0.812000   7.024444        0.553636   \n",
       "123        million second    0.887500   7.448333        0.484091   \n",
       "71         fixed maturity    0.746667   7.826667        0.203636   \n",
       "\n",
       "     bad_score_all  count  good_nums  bad_nums  diff  \n",
       "86        4.487273   1246          4        13     9  \n",
       "130       2.155909   2101         15         6     9  \n",
       "98        6.115455   1069         10        18     8  \n",
       "135       2.741818    867         16         8     8  \n",
       "116       4.282273    846          4        12     8  \n",
       "127       6.817273   4022         10        18     8  \n",
       "76        4.080000   1214          4        12     8  \n",
       "150       4.151364   1121          4        12     8  \n",
       "85        5.616818   1022          9        16     7  \n",
       "91        4.368182    856          5        12     7  \n",
       "92        5.613182   2750          9        16     7  \n",
       "93        6.177727   3193         11        18     7  \n",
       "113       5.485000   2167         11        17     6  \n",
       "84        5.530455    861         11        17     6  \n",
       "59        3.990909    719          4        10     6  \n",
       "95        3.107727    743         16        10     6  \n",
       "107       0.266818   1129          7         1     6  \n",
       "73        2.873636    849         15         9     6  \n",
       "123       6.094091    767         12        18     6  \n",
       "71        4.269091   5280          6        12     6  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodvbad_path = os.path.join(\"data\", \"training_goodvbad\")\n",
    "if not os.path.isdir(goodvbad_path):\n",
    "    os.mkdir(goodvbad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.round(2).to_csv(\"data/training_goodvbad/{}_{}_{}_n{}-{}.csv\".format(sector[:8], score_type[:3], alpha, n_min, n_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainig data scores\n",
    "\n",
    "#Technology_envirnomental\n",
    "data_tech = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\training_goodvbad\\Technolo_env_0.5_n2-3.csv'\n",
    "\n",
    "#consumer cyclical_social\n",
    "data_consumer = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\training_goodvbad\\Consumer_soc_0.5_n2-3.csv'\n",
    "\n",
    "#financial services_governance\n",
    "data_financials = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\training_goodvbad\\Financia_gov_0.5_n2-3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tech=pd.read_csv(data_tech).iloc[:,1:]\n",
    "df_consumer=pd.read_csv(data_consumer).iloc[:,1:]\n",
    "df_financials=pd.read_csv(data_financials).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tech.isGood.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    91\n",
       " 0    79\n",
       "-1    30\n",
       "Name: isGood, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consumer.isGood.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load validation companies\n",
    "\n",
    "#consumer cyclical_social\n",
    "validation_cyclical_data = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\validation_data\\Consumer_soc_0.5.csv'\n",
    "\n",
    "#Technology_envirnomental\n",
    "validation_tech_data = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\validation_data\\Technolo_env_0.5.csv'\n",
    "\n",
    "#financial services_governance\n",
    "validation_financials_data = r'C:\\Users\\Mohammed Al Harmoudi\\Documents\\GitHub\\esg_nlp\\data\\validation_data\\Financia_gov_0.5.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_cyc=pd.read_csv(validation_cyclical_data, usecols=[1,2])\n",
    "validation_tech=pd.read_csv(validation_tech_data, usecols=[1,2])\n",
    "validation_financials=pd.read_csv(validation_financials_data, usecols=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv(os.path.join(\"data\", \"tickers.csv\"))\n",
    "\n",
    "def get_cik(ticker):\n",
    "    \"\"\" Get the cik for the ticker specified by the input argument \n",
    "    Input:\n",
    "        ticker(str): ticker of the company e.g. \"FB\"\n",
    "    \"\"\"\n",
    "    return ticker_library[ticker_library.ticker == ticker].secfilings.values[0][-10:]\n",
    "    \n",
    "def ngrams(s, n):\n",
    "    \"\"\" Get all the n-gram for input texts s\n",
    "    Input:\n",
    "        s (str): A string of texts with each word separated by a whitespace\n",
    "        n (int): n-gram to extract\n",
    "    Return:\n",
    "        [str]: A list of string in the following format ([['a', 'b'], ['b', 'c'], ['c', 'd']])\n",
    "    \"\"\"\n",
    "    \n",
    "    s = s.split(' ')\n",
    "    output = []\n",
    "    for i in range(len(s) - n + 1):\n",
    "        output.append(s[i:i+n])\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_count(doc, df_dict, n_min, n_max):\n",
    "    \"\"\" Count the number of good and bad words occurred in the document\n",
    "    Input:\n",
    "        doc (str): A string with all the words in the documents\n",
    "        df_dict (pd.DataFrame): A DataFrame with word and isGood column, generated by previous section\n",
    "        n_min, n_max (int): specify the ngram range used to generate the dictionary, should be consistent with how df_dict is generated\n",
    "    Return:\n",
    "        (dict): A dictionary with value good_count and bad_count\n",
    "    \"\"\"\n",
    "    # grams = doc.split()\n",
    "\n",
    "    grams = []\n",
    "    for n in range(n_min, n_max + 1):\n",
    "        grams.extend([' '.join(li) for li in ngrams(doc, n)])\n",
    "\n",
    "    good_count = bad_count = 0\n",
    "    s = 0\n",
    "    \n",
    "    for g in grams:\n",
    "        if g in df_dict[\"word\"].values:\n",
    "            val = df_dict[df_dict[\"word\"] == g][\"isGood\"].values\n",
    "            if val > 0:\n",
    "                good_count += 1\n",
    "            elif val <= 0:\n",
    "                bad_count += 1\n",
    "            s += val\n",
    "    print(s)\n",
    "    return {\"good_count\": good_count, \"bad_count\": bad_count, \"score\": s}\n",
    "\n",
    "def normalize(array):\n",
    "    mean = np.mean(array)\n",
    "    std = np.std(array)\n",
    "\n",
    "    return (array - mean) / std\n",
    "\n",
    "    \n",
    "def validation(df_topk, val_tickers, score_scheme=\"binary\", alpha=0.3):\n",
    "    \"\"\" Perform the validation step\n",
    "    The validation rationale: Companies whose score are in upper 50% group are considered \"bad\" companies and the corresponding val_true = 1; 0 otherwise (in lower 50% group, which is considered a good company)\n",
    "    Input:\n",
    "        df_topk (pd.DataFrame): containes the sector specific dict\n",
    "        val_tickers (list): A list of tickers to be validated\n",
    "        score_scheme: score_scheme in (\"binary\", \"ratio\", \"ratio_idf\")\n",
    "    \"\"\"\n",
    "    assert score_scheme in (\"binary\", \"ratio\", \"ratio_idf\", \"ratio_norm\", \"ratio_kernel\")\n",
    "    if score_scheme == \"binary\":\n",
    "        diff = df_topk[\"good_nums\"] - df_topk[\"bad_nums\"]\n",
    "        upper_threshold = np.quantile(diff, 1 - alpha)\n",
    "        lower_threshold = np.quantile(diff, alpha)\n",
    "\n",
    "        df_topk[\"isGood\"] = diff.apply(lambda x: 1 if x > upper_threshold else (\n",
    "        -1 if x < lower_threshold else 0))\n",
    "    elif score_scheme == \"ratio\":\n",
    "        # log(good_count / (bad_count + 1))\n",
    "        # Make sure 80/40 and 40/80 have same magnitude after transformation\n",
    "        df_topk[\"isGood\"] = np.log2((df_topk[\"good_nums\"] + 1) / (df_topk[\"bad_nums\"] + 1))\n",
    "\n",
    "    # elif score_scheme == \"ratio_idf\":\n",
    "    #     # log(good_count / (bad_count + 1))\n",
    "    #     # Make sure 80/40 and 40/80 have same magnitude after transformation\n",
    "    #     total = df_topk[\"good_nums\"].values + df_topk[\"bad_nums\"].values\n",
    "    #     ma = np.max(total)\n",
    "    #     df_topk[\"isGood\"] = ((df_topk[\"good_nums\"] + 1) / (df_topk[\"bad_nums\"] + 1)) * np.log(ma / total)\n",
    "\n",
    "    elif score_scheme == \"ratio_norm\":\n",
    "        # log(good_normalization / bad_normalization)\n",
    "        good_norm = df_topk[\"good_nums\"].values\n",
    "        bad_norm = df_topk[\"bad_nums\"].values\n",
    "        df_topk[\"isGood\"] = np.log2((good_norm + 1)/(bad_norm + 1))\n",
    "    \n",
    "    elif score_scheme == \"ratio_kernel\":\n",
    "        # good_nums / (bad_nums + 1) / total\n",
    "        good_norm = df_topk[\"good_nums\"].values\n",
    "        bad_norm = df_topk[\"bad_nums\"].values\n",
    "        total = df_topk[\"good_nums\"].values + df_topk[\"bad_nums\"].values\n",
    "        ma = np.max(total)\n",
    "        weights = 1 - ((total - ma) ** 2 / (ma ** 2))       \n",
    "        # weight function rationale: Words with high or low occurrence -> not preferrable\n",
    "        # values in between should have higher weights\n",
    "        df_topk[\"isGood\"] = np.log2((good_norm + 1)/(bad_norm + 1) * weights)\n",
    "\n",
    "\n",
    "    print(df_topk)\n",
    "    # 1 if good_nums - bad_nums > threshold; -1 if good_nums - bad_nums < -threshold; 0 otherwise\n",
    "    val_ciks = [get_cik(ticker) for ticker in val_tickers]\n",
    "    \n",
    "    ret_texts = get_texts(val_ciks, val_tickers) \n",
    "\n",
    "    val_pred = []\n",
    "    for doc in tqdm(ret_texts[\"docs\"]):\n",
    "        ret = get_count(doc, df_topk[[\"word\", \"isGood\"]], 2, 3)\n",
    "\n",
    "        # if ret[\"good_count\"] - ret[\"bad_count\"] > 0:\n",
    "        #     val_pred.append(1)\n",
    "        # else:\n",
    "        #     val_pred.append(0)\n",
    "        if ret[\"score\"] > 0:\n",
    "            val_pred.append(1)\n",
    "        else:\n",
    "            val_pred.append(0)\n",
    "    \n",
    "    print(\"val_pred: {}\".format(val_pred))\n",
    "    \n",
    "    return val_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 440.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# To remove all the previous files earlier than 2020\n",
    "for cik in tqdm(bad_cik):\n",
    "    tenk_path = os.path.join(\"data\", \"10k\", cik, \"rawtext\")\n",
    "    all_raws = os.listdir(tenk_path)\n",
    "    for filename in all_raws:\n",
    "        if filename[0] == '.':\n",
    "            continue\n",
    "        year = int(filename.split('_')[1].split('-')[0])\n",
    "        # print(year)\n",
    "        if year < 2020:\n",
    "            # print(os.path.join(tenk_path, filename))\n",
    "            os.remove(os.path.join(tenk_path, filename))\n",
    "    \n",
    "    tenq_path = os.path.join(\"data\", \"10q\", cik, \"rawtext\")\n",
    "    all_raws = os.listdir(tenq_path)\n",
    "    for filename in all_raws:\n",
    "        if filename[0] == '.':\n",
    "            continue\n",
    "        year = int(filename.split('_')[1].split('-')[0])\n",
    "        # print(year)\n",
    "        if year < 2020:\n",
    "            # print(os.path.join(tenk_path, filename))\n",
    "            os.remove(os.path.join(tenq_path, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File energy_good_vs_bad_uni_bi_tri.csv does not exist: 'energy_good_vs_bad_uni_bi_tri.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-234-c9dba302b136>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"energy_good_vs_bad_uni_bi_tri.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File energy_good_vs_bad_uni_bi_tri.csv does not exist: 'energy_good_vs_bad_uni_bi_tri.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"energy_good_vs_bad_uni_bi_tri.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation for approach 1 (tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ciks(tickers):\n",
    "    ciks = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        ciks.append(get_cik(ticker))\n",
    "\n",
    "    return ciks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dict_goodvbad(good_ticker, bad_ticker, sector, score_type, rerun=False):\n",
    "    path = os.path.join(\"data\", \"goodvbad\", \"train\", \"{}_{}.csv\".format(sector, score_type))\n",
    "    if not rerun and os.path.exists(path):\n",
    "        dict_goodvbad = pd.read_csv(path, index_col=0)\n",
    "    else:\n",
    "        print(\"Train {} {}\".format(sector, score_type))\n",
    "\n",
    "        good_cik = get_ciks(good_ticker)\n",
    "        bad_cik = get_ciks(bad_ticker)\n",
    "\n",
    "        ret_good = get_texts(good_cik, good_ticker)\n",
    "        ret_bad = get_texts(bad_cik, bad_ticker)\n",
    "\n",
    "        good_docs = ret_good[\"docs\"]\n",
    "        bad_docs = ret_bad[\"docs\"]\n",
    "\n",
    "        # for t in not_listed:\n",
    "        #     if t in bad_companies:\n",
    "        #         bad_companies.remove(t)\n",
    "        #     if t in good_companies:\n",
    "        #         good_companies.remove(t)\n",
    "        n_min = 2\n",
    "        n_max = 3\n",
    "        cv = CountVectorizer(max_df=0.7, stop_words=stop_words, max_features=200, ngram_range=(n_min, n_max))\n",
    "        word_count_vector = cv.fit_transform(good_docs + bad_docs)\n",
    "        count_feature = word_count_vector.toarray().sum(axis=0)\n",
    "        feature_names = cv.get_feature_names()\n",
    "\n",
    "        # with open('data/n_grams/{}_{}.pkl'.format(sector, score_type), 'wb') as handle:\n",
    "        #     pickle.dump(feature_names, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # d = {\"word\": [], \"good_score\": [], \"bad_score\": [], \"good_score_all\": []\n",
    "        #     , \"bad_score_all\": [], \"count\": [], \"good_nums\": [], \"bad_nums\": []}\n",
    "        d = {\"count\": [], \"good_nums\": [], \"bad_nums\": [], \"isGood\": []}\n",
    "\n",
    "        for feature_idx, word in enumerate(feature_names):\n",
    "            # good_sum = bad_sum = good_num = bad_num = 0\n",
    "            good_num = bad_num = 0\n",
    "\n",
    "            for i, doc_set in enumerate(good_docs):\n",
    "                if word in doc_set:\n",
    "                    good_num += 1\n",
    "            for i, doc_set in enumerate(bad_docs):\n",
    "                if word in doc_set:\n",
    "                    bad_num += 1\n",
    "            \n",
    "            # print(\"word: {}\".format(word))\n",
    "            \n",
    "            # if good_num:\n",
    "            #     d[\"good_score\"].append(good_sum / good_num)\n",
    "            # else:\n",
    "            #     d[\"good_score\"].append(0)\n",
    "            # if bad_num:\n",
    "            #     d[\"bad_score\"].append(bad_sum / bad_num)\n",
    "            # else:\n",
    "            #     d[\"bad_score\"].append(0)\n",
    "\n",
    "            # d[\"good_score_all\"].append(good_sum / len(good_docs))\n",
    "            # d[\"bad_score_all\"].append(bad_sum / len(bad_docs))\n",
    "\n",
    "            d[\"count\"].append(count_feature[feature_idx])\n",
    "            d[\"good_nums\"].append(good_num)\n",
    "            d[\"bad_nums\"].append(bad_num)\n",
    "\n",
    "        diff = np.array(d[\"good_nums\"]) - np.array(d[\"bad_nums\"])\n",
    "        \n",
    "        alpha = 0.3\n",
    "        upper_score = np.quantile(diff, 1 - alpha)\n",
    "        lower_score = np.quantile(diff, alpha)\n",
    "        d[\"isGood\"] = np.where(diff > upper_score, 1, 0) + np.where(diff < lower_score, -1, 0)\n",
    "\n",
    "        dict_goodvbad = pd.DataFrame(d, index=feature_names)\n",
    "        dict_goodvbad.to_csv(path)\n",
    "\n",
    "    return dict_goodvbad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dict_tfidf(good_ticker, bad_ticker, sector, score_type, rerun=False):\n",
    "    path = os.path.join(\"data\", \"tfidf_scores\", \"train\", \"{}_{}.csv\".format(sector, score_type))\n",
    "    if not rerun and os.path.exists(path):\n",
    "        df_tfidf = pd.read_csv(path, index_col=0)\n",
    "    else:\n",
    "        print(\"Train {} {}\".format(sector, score_type))\n",
    "        tickers = good_ticker + bad_ticker\n",
    "        ciks = get_ciks(tickers)\n",
    "\n",
    "        esgs = df_esg_score[df_esg_score[\"Company\"].isin(tickers)][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "\n",
    "        # for t in not_listed:\n",
    "        #     if t in good_ticker or t in bad_ticker:\n",
    "        #         esgs = esgs.drop(esgs[esgs[\"Company\"] == t].index)\n",
    "\n",
    "        ret = get_texts(ciks, tickers)\n",
    "        docs = ret[\"docs\"]\n",
    "\n",
    "        cv = CountVectorizer(max_df=0.8, stop_words=stop_words, max_features=1000)\n",
    "        word_count_vector = cv.fit_transform(docs)\n",
    "\n",
    "        tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "        tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "        feature_names = cv.get_feature_names()\n",
    "\n",
    "        df_doc_word = pd.DataFrame(columns=feature_names, index=tickers)\n",
    "\n",
    "        for i, ticker in tqdm(enumerate(tickers)):\n",
    "            tf_idf_vector = tfidf_transformer.transform(cv.transform([docs[i]]))\n",
    "            \n",
    "            coo_matrix = tf_idf_vector.tocoo()\n",
    "            # coo_matrix: A sparse matrix in which coo_matrix.col stores word_idx, coo_matrix.data stores tfidf score\n",
    "            \n",
    "            tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "            for word_idx, tfidf in tuples:\n",
    "                df_doc_word.at[ticker, feature_names[word_idx]] = tfidf\n",
    "\n",
    "        df_doc_word = df_doc_word.iloc[:, df_doc_word.columns.isin(words.words())]\n",
    "        df_doc_word = df_doc_word.fillna(0)\n",
    "\n",
    "        feature_names = [name for name in feature_names if name in words.words()]\n",
    "\n",
    "        df_tfidf = pd.DataFrame(columns=[\"{}_beta\".format(score_type)], index=feature_names)\n",
    "\n",
    "        # for typ in [\"social\", \"governance\", \"environment\"]:\n",
    "        score = esgs[score_type]\n",
    "        slopes = []\n",
    "        \n",
    "        for word in feature_names:\n",
    "            tfidfs = df_doc_word[word].values.astype(float)\n",
    "            slope, intercept, *_ = linregress(tfidfs, score)\n",
    "            slopes.append(slope)\n",
    "        df_tfidf[\"{}_beta\".format(score_type)] = slopes\n",
    "\n",
    "        cols = df_tfidf.columns\n",
    "        alpha = 0.3\n",
    "\n",
    "        for col in cols: \n",
    "            betas = df_tfidf[col]\n",
    "            score_type = col.split('_')[0]\n",
    "            \n",
    "            upper_score = np.quantile(betas, 1 - alpha)\n",
    "            lower_score = np.quantile(betas, alpha)\n",
    "            \n",
    "            is_good = np.where(betas < lower_score, 1, 0) + np.where(betas > upper_score, -1, 0)\n",
    "            \n",
    "            df_tfidf[\"isGood\"] = is_good\n",
    "\n",
    "        df_tfidf.to_csv(path)\n",
    "    return df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_tfidf(df_tfidf, val_tickers):\n",
    "    \"\"\" Perform the validation step\n",
    "    The validation rationale: Companies whose score are in upper 50% group are considered \"bad\" companies and the corresponding val_true = 1; 0 otherwise (in lower 50% group, which is considered a good company)\n",
    "    Input:\n",
    "        df_topk (pd.DataFrame): containes the sector specific dict\n",
    "        val_tickers (list): A list of tickers to be validated\n",
    "    \"\"\"\n",
    "    df_tfidf[\"word\"] = df_tfidf.index\n",
    "    \n",
    "    # 1 if good_nums - bad_nums > threshold; -1 if good_nums - bad_nums < -threshold; 0 otherwise\n",
    "    val_ciks = [get_cik(ticker) for ticker in val_tickers]\n",
    "    \n",
    "    ret_texts = get_texts(val_ciks, val_tickers)\n",
    "\n",
    "    val_pred = []\n",
    "    for i, doc in tqdm(enumerate(ret_texts[\"docs\"])):\n",
    "        ret = get_count(doc, df_tfidf[[\"word\", \"isGood\"]])\n",
    "        print(val_tickers[i])\n",
    "        print(ret)\n",
    "\n",
    "        if ret[\"good_count\"] - ret[\"bad_count\"] > 0:\n",
    "            val_pred.append(1)\n",
    "        else:\n",
    "            val_pred.append(0)\n",
    "    \n",
    "    print(\"val_pred: {}\".format(val_pred))\n",
    "    \n",
    "    return val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_report(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    prec = cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "    rec = cm[1][1]/(cm[1][1]+cm[0][1])\n",
    "    acc = (cm[1][1] + cm[0][0]) /(cm[1][0]+cm[0][1] + cm[1][1] + cm[0][0])\n",
    "\n",
    "    print(\"precision: \\n{}\".format(prec))\n",
    "    print(\"recall: \\n{}\".format(rec))\n",
    "    print(\"accuracy: \\n{}\".format(acc))\n",
    "    print(\"Confusion Matrix: \\n{}\".format(cm))\n",
    "\n",
    "    return {\"cm\": cm, \"precision\": prec, \"recall\": rec, \"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_precision = pd.DataFrame(index=sectors, columns=score_types)\n",
    "df_val_recall = pd.DataFrame(index=sectors, columns=score_types)\n",
    "df_val_accuracy = pd.DataFrame(index=sectors, columns=score_types)\n",
    "cms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sectors = ['Consumer Cyclical', 'Energy', 'Industrials', 'Healthcare',\n",
    "#        'Basic Materials', 'Consumer Defensive', 'Utilities', 'Technology',\n",
    "#        'Financial Services', 'Communication Services', 'Real Estate']\n",
    "# sectors = ['Technology', 'Financial Services']\n",
    "# sectors = [\"Energy\"]\n",
    "sectors = [\"Consumer Cyclical\"]\n",
    "# score_types = [\"governanceScore\", \"environmentScore\", \"socialScore\"]\n",
    "score_types = [\"socialScore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = (('Technology', \"socialScore\"), ('Technology', \"governanceScore\"), ('Financial Services', \"governanceScore\"), ('Financial Services', \"socialScore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = \"goodvbad\" # (\"tfidf\", \"goodvbad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dicts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer Cyclical socialScore\n",
      "                     count  good_nums  bad_nums    isGood                 word\n",
      "accompani note         467          0         1  1.567747       accompani note\n",
      "account principl       576          0         1  1.567747     account principl\n",
      "advers affect          819          0         1  1.567747        advers affect\n",
      "affect oper            569          9         9  0.245122          affect oper\n",
      "aggregate principal    682          9         7  0.453632  aggregate principal\n",
      "...                    ...        ...       ...       ...                  ...\n",
      "web site               493          0         1  1.567747             web site\n",
      "websit develop         724          0         1  1.567747       websit develop\n",
      "year end               838         12        11  0.000000             year end\n",
      "year end decemb        746          1         1  2.442347      year end decemb\n",
      "year ended march       479          2         1  3.055323     year ended march\n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 40.85it/s]\n",
      "  0%|          | 0/12 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cx/74c09p4917dbnxyclq4tvqkc0000gn/T/ipykernel_29798/2171802230.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# val_pred = validation_tfidf(df_dict, val_tickers)   # df is the dictionary with good_num, bad_num, diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_tickers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_scheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ratio_idf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mval_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_good\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_bad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cx/74c09p4917dbnxyclq4tvqkc0000gn/T/ipykernel_29798/3594377915.py\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(df_topk, val_tickers, score_scheme, alpha)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"docs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_topk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"isGood\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# if ret[\"good_count\"] - ret[\"bad_count\"] > 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cx/74c09p4917dbnxyclq4tvqkc0000gn/T/ipykernel_29798/3594377915.py\u001b[0m in \u001b[0;36mget_count\u001b[0;34m(doc, df_dict, n_min, n_max)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"isGood\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3423\u001b[0m             \u001b[0;31m# shortcut if the key is in columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3424\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3425\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4537\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4538\u001b[0m         \"\"\"\n\u001b[1;32m   4539\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for sector in sectors:\n",
    "    for score_type in score_types:\n",
    "        print(\"{} {}\".format(sector, score_type))\n",
    "        esgs = df_esg_score[df_esg_score[\"sector\"] == sector][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "        score = esgs[score_type]\n",
    "        alpha = 0.3\n",
    "        upper_score = np.quantile(score, 1 - alpha)\n",
    "        lower_score = np.quantile(score, alpha)\n",
    "\n",
    "        good_companies = list(esgs[esgs[score_type] < lower_score][\"Company\"].values)\n",
    "        bad_companies = list(esgs[esgs[score_type] > upper_score][\"Company\"].values)\n",
    "                \n",
    "        #training set\n",
    "        train_good = random.sample(list(good_companies), int(len(good_companies) * 0.7))\n",
    "        train_bad = random.sample(list(bad_companies), int(len(bad_companies) * 0.7))\n",
    "\n",
    "        if approach == \"goodvbad\":\n",
    "            df_dict = train_dict_goodvbad(train_good, train_bad, sector, score_type, rerun=False)\n",
    "            \n",
    "            if \"word\" not in df_dict.columns:\n",
    "                df_dict[\"word\"] = df_dict.index.to_numpy()\n",
    "\n",
    "        if approach == \"tfidf\":\n",
    "            df_dict = train_dict_tfidf(train_good, train_bad, sector, score_type, rerun=False)\n",
    "        \n",
    "        all_dicts.append(df_dict)\n",
    "\n",
    "        #validation set\n",
    "        validate_good = [ticker for ticker in good_companies if ticker not in train_good]\n",
    "        validate_bad = [ticker for ticker in bad_companies if ticker not in train_bad]\n",
    "\n",
    "        val_tickers = validate_good + validate_bad\n",
    "        \n",
    "        # val_pred = validation_tfidf(df_dict, val_tickers)   # df is the dictionary with good_num, bad_num, diff\n",
    "        val_pred = validation(df_dict, val_tickers, score_scheme=\"ratio_idf\")\n",
    "        val_true = [1] * len(validate_good) + [0] * len(validate_bad)\n",
    "\n",
    "        val_performance = get_report(val_true, val_pred)\n",
    "        # df_val_precision.at[sector, score_type] = val_performance[\"precision\"]\n",
    "        # df_val_recall.at[sector, score_type] = val_performance[\"recall\"]\n",
    "        # df_val_accuracy.at[sector, score_type] = val_performance[\"accuracy\"]\n",
    "        # cms.append(val_performance[\"cm\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>isGood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accompani note</th>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account principl</th>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advers affect</th>\n",
       "      <td>819</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affect oper</th>\n",
       "      <td>569</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregate principal</th>\n",
       "      <td>682</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web site</th>\n",
       "      <td>493</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>websit develop</th>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year end</th>\n",
       "      <td>838</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year end decemb</th>\n",
       "      <td>746</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year ended march</th>\n",
       "      <td>479</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count  good_nums  bad_nums  isGood\n",
       "accompani note         467          0         1       0\n",
       "account principl       576          0         1       0\n",
       "advers affect          819          0         1       0\n",
       "affect oper            569          9         9       0\n",
       "aggregate principal    682          9         7       0\n",
       "...                    ...        ...       ...     ...\n",
       "web site               493          0         1       0\n",
       "websit develop         724          0         1       0\n",
       "year end               838         12        11       0\n",
       "year end decemb        746          1         1       0\n",
       "year ended march       479          2         1       0\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    129\n",
       " 1     56\n",
       "-1     15\n",
       "Name: isGood, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[\"isGood\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>good_nums</th>\n",
       "      <th>bad_nums</th>\n",
       "      <th>isGood</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accompani note</th>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>accompani note</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account principl</th>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>account principl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advers affect</th>\n",
       "      <td>819</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>advers affect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affect oper</th>\n",
       "      <td>569</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>affect oper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aggregate principal</th>\n",
       "      <td>682</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>aggregate principal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count  good_nums  bad_nums  isGood                 word\n",
       "accompani note         467          0         1       0       accompani note\n",
       "account principl       576          0         1       0     account principl\n",
       "advers affect          819          0         1       0        advers affect\n",
       "affect oper            569          9         9       0          affect oper\n",
       "aggregate principal    682          9         7       1  aggregate principal"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>governanceScore</th>\n",
       "      <th>environmentScore</th>\n",
       "      <th>socialScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrials</th>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Services</th>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   governanceScore environmentScore socialScore\n",
       "Consumer Cyclical              0.5             0.25    0.444444\n",
       "Industrials                    0.4              NaN         NaN\n",
       "Utilities                      0.0              0.5         NaN\n",
       "Technology                     0.5              NaN        0.25\n",
       "Financial Services            0.25              NaN         0.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>governanceScore</th>\n",
       "      <th>environmentScore</th>\n",
       "      <th>socialScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrials</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Services</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   governanceScore environmentScore socialScore\n",
       "Consumer Cyclical              0.5         0.333333    0.416667\n",
       "Industrials               0.416667              NaN         NaN\n",
       "Utilities                      0.0              0.5         NaN\n",
       "Technology                     0.5              NaN    0.333333\n",
       "Financial Services        0.166667              NaN    0.083333"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>governanceScore</th>\n",
       "      <th>environmentScore</th>\n",
       "      <th>socialScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Consumer Cyclical</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrials</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Services</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   governanceScore environmentScore socialScore\n",
       "Consumer Cyclical         0.333333         0.166667    0.666667\n",
       "Industrials               0.333333              NaN         NaN\n",
       "Utilities                      0.0         0.666667         NaN\n",
       "Technology                     0.5              NaN    0.166667\n",
       "Financial Services        0.333333              NaN         0.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4, 2],\n",
       "        [4, 2]]),\n",
       " array([[3, 3],\n",
       "        [5, 1]]),\n",
       " array([[1, 5],\n",
       "        [2, 4]]),\n",
       " array([[1, 5],\n",
       "        [3, 3]]),\n",
       " array([[3, 3],\n",
       "        [4, 2]]),\n",
       " array([[0, 3],\n",
       "        [3, 0]]),\n",
       " array([[1, 2],\n",
       "        [1, 2]]),\n",
       " array([[3, 3],\n",
       "        [3, 3]]),\n",
       " array([[3, 3],\n",
       "        [5, 1]]),\n",
       " array([[0, 6],\n",
       "        [4, 2]]),\n",
       " array([[1, 5],\n",
       "        [6, 0]])]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>governanceScore</th>\n",
       "      <th>environmentScore</th>\n",
       "      <th>socialScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Energy</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       governanceScore environmentScore socialScore\n",
       "Energy             0.5              0.5         0.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Consumer Cyclical socialScore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 27.44it/s]\n",
      "/Users/luckywang/Documents/Document/Course Material/Fall 2021/esg_nlp/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['10'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "24it [00:02,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.06955651714321\n",
      "-53.54111784783206\n",
      "             socialScore_beta  isGood\n",
      "accept              34.720252       0\n",
      "accessory          -39.541716       0\n",
      "accord            -172.654997       1\n",
      "achievement        127.554267      -1\n",
      "actuarial          439.797658      -1\n",
      "add                218.156139      -1\n",
      "adjust             280.132074      -1\n",
      "adopt               83.043171      -1\n",
      "advance            -29.159821       0\n",
      "advanced            37.672048       0\n",
      "advertising         77.588309       0\n",
      "affiliate           -1.181519       0\n",
      "age                 14.487396       0\n",
      "air                 23.887095       0\n",
      "aluminum            13.189829       0\n",
      "amend             -689.686912       1\n",
      "amort              -98.618887       1\n",
      "analyst             16.867392       0\n",
      "apparel              9.501550       0\n",
      "appear             189.283871      -1\n",
      "approval           489.704555      -1\n",
      "arise              356.007643      -1\n",
      "asp                  4.514310       0\n",
      "assert             504.370988      -1\n",
      "assess            -154.142831       1\n",
      "assigned            -0.481985       0\n",
      "associate           11.596587       0\n",
      "attack             465.401898      -1\n",
      "attorney          -174.666265       1\n",
      "auction           -456.359743       1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 37.69it/s]\n",
      "1it [00:03,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBHS\n",
      "{'good_count': 209, 'bad_count': 817}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:06,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHK\n",
      "{'good_count': 512, 'bad_count': 1309}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:13,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL\n",
      "{'good_count': 1113, 'bad_count': 1737}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:16,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPC\n",
      "{'good_count': 367, 'bad_count': 916}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:18,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOW\n",
      "{'good_count': 341, 'bad_count': 679}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:24,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAS\n",
      "{'good_count': 2015, 'bad_count': 1818}\n",
      "F\n",
      "{'good_count': 0, 'bad_count': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:32,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA\n",
      "{'good_count': 1429, 'bad_count': 2502}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:36,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPZ\n",
      "{'good_count': 370, 'bad_count': 888}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:42,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPE\n",
      "{'good_count': 2924, 'bad_count': 2172}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:46,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAR\n",
      "{'good_count': 2637, 'bad_count': 1791}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:48,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROL\n",
      "{'good_count': 255, 'bad_count': 766}\n",
      "val_pred: [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sector = 'Consumer Cyclical'\n",
    "score_types = \"environmentScore\"\n",
    "\n",
    "esgs = df_esg_score[df_esg_score[\"sector\"] == sector][[\"Company\", \"socialScore\", \"governanceScore\", \"environmentScore\"]]\n",
    "score = esgs[score_type]\n",
    "alpha = 0.3\n",
    "upper_score = np.quantile(score, 1 - alpha)\n",
    "lower_score = np.quantile(score, alpha)\n",
    "\n",
    "bad_companies = list(esgs[esgs[score_type] > upper_score][\"Company\"].values)\n",
    "good_companies = list(esgs[esgs[score_type] < lower_score][\"Company\"].values)\n",
    "\n",
    "for t in not_listed:\n",
    "    if t in bad_companies:\n",
    "        bad_companies.remove(t)\n",
    "    if t in good_companies:\n",
    "        good_companies.remove(t)\n",
    "        \n",
    "#training set\n",
    "train_good = random.sample(list(good_companies), int(len(good_companies)*0.7))\n",
    "train_bad = random.sample(list(bad_companies), int(len(bad_companies)*0.7))\n",
    "\n",
    "df_tfidf = train_dict_tfidf(train_good, train_bad, sector, score_type, rerun=False)\n",
    "\n",
    "#validation set\n",
    "validate_good = [ticker for ticker in good_companies if ticker not in train_good]\n",
    "validate_bad = [ticker for ticker in bad_companies if ticker not in train_bad]\n",
    "\n",
    "val_tickers = validate_good + validate_bad\n",
    "\n",
    "val_pred = validation_tfidf(df_tfidf, val_tickers)   # df is the dictionary with good_num, bad_num, diff\n",
    "val_true = [1] * len(validate_good) + [0] * len(validate_bad)\n",
    "\n",
    "# val_performance = get_report(val_true, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: \n",
      "0.16666666666666666\n",
      "recall: \n",
      "0.3333333333333333\n",
      "accuracy: \n",
      "0.4166666666666667\n",
      "Confusion Matrix: \n",
      "[[4 2]\n",
      " [5 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cm': array([[4, 2],\n",
       "        [5, 1]]),\n",
       " 'precision': 0.16666666666666666,\n",
       " 'recall': 0.3333333333333333,\n",
       " 'accuracy': 0.4166666666666667}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_report(val_true, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumer cyclical sector, social\n",
    "val_tickers_cyc = (pd.concat([validation_cyc['good'], validation_cyc['bad']])).tolist()\n",
    "\n",
    "# TODO: Update to the actual tickers to test\n",
    "# val_tickers = [\"FB\", \"GOOG\"] # should be a list of tickers you split into test set\n",
    "\n",
    "val_ciks = [get_cik(ticker) for ticker in val_tickers_cyc]\n",
    "\n",
    "val_pred = validation(df_consumer, val_tickers_cyc, 2)   # df is the dictionary with good_num, bad_num, diff\n",
    "\n",
    "# val_true (list): A list of true labels for each companies (1 for good company, 0 for bad)\n",
    "val_true = np.concatenate([([i]*len(validation_cyc['good'])) for i in [1,0]], axis=0).tolist()\n",
    "# val_true = [1, 1]\n",
    "cm = confusion_matrix(val_true, val_pred)\n",
    "prec = cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "rec = cm[1][1]/(cm[1][1]+cm[0][1])\n",
    "acc = (cm[1][1] + cm[0][0]) /(cm[1][0]+cm[0][1] + cm[1][1] + cm[0][0])\n",
    "\n",
    "print(\"precision: \\n{}\".format(prec))\n",
    "print(\"recall: \\n{}\".format(rec))\n",
    "print(\"accuracy: \\n{}\".format(acc))\n",
    "print(\"Confusion Matrix: \\n{}\".format(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pickle folder for specific ciks\n",
    "import shutil\n",
    "def remove_pickle(ciks):\n",
    "    for cik in ciks:\n",
    "        for file_type in (\"10k\", \"10q\"):\n",
    "            pickle_path = os.path.join(\"data\", file_type, cik, \"pickle\")\n",
    "            if os.path.isdir(pickle_path):\n",
    "                shutil.rmtree(pickle_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0001519751'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_cik[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cik = get_ciks(bad_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_pickle(bad_cik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advers'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"advers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcf325ffca4e7352bcfac699b7999bb028ddd94d8390136137b75043a4ee01b0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
